{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6ae9879",
   "metadata": {
    "id": "b6ae9879"
   },
   "source": [
    "# **PROGETTO: CARCINOMA CLASSIFICATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cceb8ae",
   "metadata": {
    "id": "8cceb8ae"
   },
   "source": [
    "## *Librerie + import del dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda69af3",
   "metadata": {
    "id": "dda69af3",
    "outputId": "2e9b0a59-39e2-401d-938d-83f1220358c9"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import gc\n",
    "import os, re\n",
    "from glob import glob\n",
    "import json\n",
    "import textwrap\n",
    "import math\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassAccuracy,\n",
    "    MulticlassConfusionMatrix,\n",
    ")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "from densatio import CustomPooling2d\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee64e145",
   "metadata": {
    "id": "ee64e145",
    "outputId": "3e795b48-5439-40b2-c497-c1ad659649ac"
   },
   "outputs": [],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9e9e77",
   "metadata": {
    "id": "ab9e9e77"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "BATCH_SIZE = 16\n",
    "NUM_CLASSES = 3\n",
    "NUM_EPOCHS = 250\n",
    "\n",
    "LABEL_MAP = {\"not detectable\": 0, \"benign\": 1, \"malignant\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd5c090",
   "metadata": {
    "id": "9dd5c090",
    "outputId": "656ad715-1301-4a9d-e054-f0f1976ab94e"
   },
   "outputs": [],
   "source": [
    "img_dir = Path(\"dati\\data\\dataset\")\n",
    "labels_path = Path(\"dati\\data\\metadata.csv\")\n",
    "\n",
    "df = pd.read_csv(labels_path, sep=\",\")\n",
    "\n",
    "df[\"label\"] = df[\"malignant\"].map(LABEL_MAP).astype(int)\n",
    "\n",
    "print(df[[\"id\", \"malignant\", \"label\"]].head())\n",
    "print(df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38b908e",
   "metadata": {
    "id": "f38b908e"
   },
   "source": [
    "Dopo la mappatura delle etichette: ogni riga ha l’id dell’immagine, la label testuale originale e la versione numerica. In totale ho 36 immagini ‘not detectable’ (classe 0), 14 ‘benign’ (classe 1) e 12 ‘malignant’ (classe 2), quindi il dataset è un po’ sbilanciato verso la classe 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f597f64c",
   "metadata": {
    "id": "f597f64c"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacc18ca",
   "metadata": {
    "id": "eacc18ca",
    "outputId": "df83ed15-aa28-4843-d09b-b1f816ced74d"
   },
   "outputs": [],
   "source": [
    "def id2loc(id_):\n",
    "    \"\"\"Restituisce il path dell'immagine a partire dall'id.\"\"\"\n",
    "    return str(Path(img_dir) / f\"img_{id_}.png\")\n",
    "\n",
    "def id2img(id_):\n",
    "    \"\"\"Carica l'immagine (RGB) dato l'id.\"\"\"\n",
    "    return Image.open(id2loc(id_)).convert(\"RGB\")\n",
    "\n",
    "def img2arr(img):\n",
    "    \"\"\"Converte una PIL Image in array numpy.\"\"\"\n",
    "    return np.asarray(img)\n",
    "\n",
    "def id2arr(id_):\n",
    "    \"\"\"Carica l'immagine da id e la restituisce come array numpy.\"\"\"\n",
    "    return img2arr(id2img(id_))\n",
    "\n",
    "def show_images(df, n_fig=10,random=True, seed=42):\n",
    "\n",
    "    \"\"\"\n",
    "    Mostra un grid di immagini per classe (3 righe = 3 classi, n_fig colonne).\n",
    "\n",
    "    - df: DataFrame con colonne id_col, label_col\n",
    "    - n_fig: numero massimo di immagini per classe\n",
    "    - random: se True, shuffle per classe\n",
    "    - seed: random_state per la riproducibilità\n",
    "    \"\"\"\n",
    "\n",
    "    LABEL_MAP = {0: \"not detectable\", 1:\"benign\", 2:\"malignant\"}\n",
    "\n",
    "    dfs = {\n",
    "        0: df[df[\"label\"] == 0].reset_index(drop=True),\n",
    "        1: df[df[\"label\"] == 1].reset_index(drop=True),\n",
    "        2: df[df[\"label\"] == 2].reset_index(drop=True),\n",
    "    }\n",
    "\n",
    "    if random:\n",
    "        for k in dfs:\n",
    "            dfs[k] = dfs[k].sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "    # n_fig non può superare la classe più piccola:\n",
    "    # limito il numero di immagini mostrate al minimo tra le classi,\n",
    "    # così ogni classe è rappresentata con lo stesso numero di esempi.\n",
    "\n",
    "    n_fig_eff = min(n_fig, len(dfs[0]), len(dfs[1]), len(dfs[2]))\n",
    "    if n_fig_eff < n_fig:\n",
    "        print(f\"Ridotto da {n_fig} a {n_fig_eff}\")\n",
    "    n_fig = n_fig_eff\n",
    "\n",
    "    fig, axes = plt.subplots(3, n_fig, figsize=(1.6*n_fig, 6), constrained_layout=True)\n",
    "\n",
    "    for col in range(n_fig):\n",
    "        for row, lab in enumerate([0, 1, 2]):\n",
    "            img_id = dfs[lab].iloc[col][\"id\"]\n",
    "            axes[row, col].imshow(id2img(img_id))\n",
    "            axes[row, col].set_xticks([])\n",
    "            axes[row, col].set_yticks([])\n",
    "            axes[row, col].set_frame_on(True)\n",
    "\n",
    "        axes[0, 0].set_ylabel(LABEL_MAP[0], fontsize=12, rotation=90, labelpad=20)\n",
    "        axes[1, 0].set_ylabel(LABEL_MAP[1], fontsize=12, rotation=90, labelpad=20)\n",
    "        axes[2, 0].set_ylabel(LABEL_MAP[2], fontsize=12, rotation=90, labelpad=20)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "show_images(df, n_fig=10, random=True, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a6112a",
   "metadata": {
    "id": "c2a6112a",
    "outputId": "2d219f80-d290-4a5a-a2c5-40fa6b9db308"
   },
   "outputs": [],
   "source": [
    "dims = pd.DataFrame(\n",
    "    [id2arr(df.iloc[i][\"id\"]).shape for i in range(len(df))],\n",
    "    columns=[\"height\", \"width\", \"channels\"]  # np.asarray(img) → (H, W, C)\n",
    ")\n",
    "print(dims.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a855dc51",
   "metadata": {
    "id": "a855dc51"
   },
   "source": [
    "I numeri riassumono le dimensioni delle 62 immagini: tutte hanno 3 canali (quindi sono a colori, RGB) e le altezze/larghezze sono piuttosto variabili, con valori che vanno da circa 270 a 900 pixel. La media è intorno ai 465 pixel per lato, ma la deviazione standard alta indica che non sono tutte della stessa dimensione. Questo conferma che ha senso ridimensionarle a una risoluzione fissa (ad esempio 224×224) prima di usarle nel modello."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdd64e7",
   "metadata": {
    "id": "acdd64e7"
   },
   "source": [
    "## *Data augmentation*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b60286d",
   "metadata": {
    "id": "8b60286d"
   },
   "source": [
    "Si parte da un DataFrame contenente ID e label. Per ciascun campione:\n",
    "\n",
    "1. viene costruito il percorso dell’immagine a partire dall’ID;\n",
    "\n",
    "2. l’immagine viene caricata da disco e convertita in RGB;\n",
    "\n",
    "3. viene applicata la pipeline di trasformazioni: in training include anche data augmentation, mentre in validation/test prevede solo resize e normalizzazione;\n",
    "\n",
    "4. l’output viene convertito in un tensore nel formato (C, H, W) e associato alla label intera, pronta per il calcolo della loss.\n",
    "\n",
    "In questo modo, il modello riceve input uniformi per dimensione e normalizzati con mean/std calcolate sul training set; inoltre, durante l’addestramento, osserva varianti realistiche dello stesso campione grazie alle augmentations, migliorando la generalizzazione.\n",
    "\n",
    "La funzione *_denorm* consente di invertire la normalizzazione e ottenere immagini visualizzabili, utili per verificare che la pipeline di preprocessing stia producendo gli input attesi.\n",
    "\n",
    "Le augmentations adottate (rumore, flip, piccole rotazioni, variazioni di luminosità e contrasto) sono coerenti con pratiche consolidate nella letteratura sul deep learning per imaging medico, in particolare su lesioni cutanee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1ff97f",
   "metadata": {
    "id": "3d1ff97f"
   },
   "outputs": [],
   "source": [
    "def compute_mean_std(train_df, img_dir, img_size=224):\n",
    "    \"\"\"\n",
    "    Calcola mean/std SOLO sul train, in [0,1] (per canale RGB).\n",
    "    Poi queste mean/std vanno passate a tutti i dataset (train/val/test).\n",
    "    \"\"\"\n",
    "    means, stds = [], []\n",
    "\n",
    "    for _, row in tqdm(train_df.iterrows(), total=len(train_df)):\n",
    "        path = os.path.join(img_dir, f\"img_{row['id']}.png\")\n",
    "        img = cv2.imread(path)\n",
    "\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Not found: {path}\")\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (img_size, img_size))\n",
    "        img = img.astype(np.float32) / 255.0  # [0,1]\n",
    "\n",
    "        means.append(img.mean(axis=(0, 1)))\n",
    "        stds.append(img.std(axis=(0, 1)))\n",
    "\n",
    "    mean = np.mean(means, axis=0).tolist()\n",
    "    std  = np.mean(stds, axis=0).tolist()\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785e1602",
   "metadata": {
    "id": "785e1602"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset personalizzato per immagini classificate con supporto ad augmentations Albumentations.\n",
    "\n",
    "    Carica immagini da directory usando un DataFrame con colonne 'id' e 'label'.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame con colonne 'id' (int) e 'label' (int).\n",
    "        img_dir: Path alla directory contenente img_{id}.png.\n",
    "        img_size: Dimensione target (quadrata, default 224).\n",
    "        is_train: Modalità training (abilita augmentations).\n",
    "        augment: Applica augmentations se is_train=True.\n",
    "        resize: Se True -> Resize diretto a (img_size,img_size).\n",
    "                Se False -> Preserva aspect ratio con LongestMaxSize + PadIfNeeded,\n",
    "                            MA output sempre (img_size,img_size).\n",
    "        mean: Lista mean per normalizzazione (3 valori per RGB).\n",
    "        std: Lista std per normalizzazione (3 valori per RGB).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        img_dir,\n",
    "        img_size=224,\n",
    "        is_train=True,   # train/eval mode\n",
    "        augment=True,    # augmentation on/off\n",
    "        resize=True,     # resize on/off (see docstring)\n",
    "        mean=None,\n",
    "        std=None\n",
    "    ):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.img_size = img_size\n",
    "\n",
    "        self.is_train = is_train\n",
    "        self.augment = augment\n",
    "        self.resize = resize\n",
    "\n",
    "        if mean is None or std is None:\n",
    "            raise ValueError(\"Fornire mean e std calcolati SOLO sul TRAIN set con compute_mean_std().\")\n",
    "\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "        # Albumentations pipelines\n",
    "        self.transform = self._build_tf(img_size)\n",
    "        self.orig_transform = self._build_orig_tf(img_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_ = self.df.loc[idx, \"id\"]\n",
    "        label = int(self.df.loc[idx, \"label\"])\n",
    "\n",
    "        path = os.path.join(self.img_dir, f\"img_{id_}.png\")\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Image not found: {path}\")\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # numpy uint8 (H,W,3)\n",
    "\n",
    "        # main version (aug + final resize/pad + float + norm)\n",
    "        img_aug = self.transform(image=img)[\"image\"]\n",
    "        img_aug = self._to_tensor(img_aug)\n",
    "\n",
    "        y = torch.tensor(label, dtype=torch.long)\n",
    "        return img_aug, y\n",
    "\n",
    "    def _final_resize_ops(self, img_size):\n",
    "        \"\"\"\n",
    "        Always produce (img_size, img_size):\n",
    "        - if resize=True: direct resize\n",
    "        - if resize=False: keep aspect ratio + pad to square\n",
    "        \"\"\"\n",
    "        if self.resize:\n",
    "            return [A.Resize(img_size, img_size)]\n",
    "        else:\n",
    "            return [\n",
    "                A.LongestMaxSize(img_size),\n",
    "                A.PadIfNeeded(img_size, img_size, border_mode=cv2.BORDER_CONSTANT),\n",
    "            ]\n",
    "\n",
    "    def _build_orig_tf(self, img_size):\n",
    "        \"\"\"Pipeline per immagine originale: sempre size fissa (utile per debug).\"\"\"\n",
    "        tf = []\n",
    "        tf.extend(self._final_resize_ops(img_size))\n",
    "        return A.Compose(tf)\n",
    "\n",
    "    def _build_tf(self, img_size):\n",
    "        \"\"\"\n",
    "        Pipeline principale per training.\n",
    "\n",
    "        Sequenza:\n",
    "        - Augmentations (se train e augment=True)\n",
    "        - Final resize/pad (SEMPRE: output img_size x img_size)\n",
    "        - ToFloat [0,1]\n",
    "        - Normalize con mean/std forniti\n",
    "        \"\"\"\n",
    "        tf = []\n",
    "\n",
    "        # 1) Augmentations (solo train)\n",
    "        if self.is_train and self.augment:\n",
    "            tf.append(self._aug())\n",
    "\n",
    "        # 2) Final resize/pad (sempre)\n",
    "        tf.extend(self._final_resize_ops(img_size))\n",
    "\n",
    "        # 3) Float + Normalize\n",
    "        tf.append(A.ToFloat(max_value=255.0))  # [0,1]\n",
    "        tf.append(A.Normalize(mean=self.mean, std=self.std, max_pixel_value=1.0))\n",
    "\n",
    "        return A.Compose(tf)\n",
    "\n",
    "    def _to_tensor(self, img_np):\n",
    "        \"\"\"Converte numpy (H,W,C) -> torch (C,H,W) float32.\"\"\"\n",
    "        if img_np.dtype != np.float32:\n",
    "            img_np = img_np.astype(np.float32)\n",
    "        t = torch.from_numpy(img_np).permute(2, 0, 1).contiguous()\n",
    "        return t\n",
    "\n",
    "    def _aug(self):\n",
    "        \"\"\"Augmentations randomizzate.\"\"\"\n",
    "        families = [\n",
    "            A.OneOf([\n",
    "                A.GaussNoise(noise_scale_factor=0.1, p=1.0),\n",
    "                A.MultiplicativeNoise(multiplier=(0.85, 1.15), per_channel=True),\n",
    "                A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5)),\n",
    "            ], p=1.0),\n",
    "\n",
    "            A.OneOf([\n",
    "                A.HorizontalFlip(),\n",
    "                A.VerticalFlip(),\n",
    "                A.RandomRotate90(),\n",
    "            ], p=1.0),\n",
    "\n",
    "            A.OneOf([\n",
    "                A.RandomBrightnessContrast(0.15, 0.15),\n",
    "                A.RandomGamma(gamma_limit=(80, 120)),\n",
    "                A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8)),\n",
    "            ], p=1.0),\n",
    "\n",
    "            A.OneOf([\n",
    "                A.GaussianBlur(blur_limit=(3, 7)),\n",
    "                A.MotionBlur(blur_limit=5),\n",
    "                A.Sharpen(alpha=(0.1, 0.35), lightness=(0.9, 1.1)),\n",
    "            ], p=1.0),\n",
    "\n",
    "            A.OneOf([\n",
    "                A.Rotate(limit=15, border_mode=cv2.BORDER_CONSTANT),\n",
    "                A.ShiftScaleRotate(\n",
    "                    shift_limit=0.04,\n",
    "                    scale_limit=0.06,\n",
    "                    rotate_limit=0,\n",
    "                    border_mode=cv2.BORDER_CONSTANT\n",
    "                ),\n",
    "                A.GridDistortion(num_steps=5, distort_limit=0.2),\n",
    "            ], p=1.0),\n",
    "\n",
    "            A.OneOf([\n",
    "                A.CoarseDropout(num_holes_range=(1, 8), hole_height_range=(8, 24), hole_width_range=(8, 24), fill=0, p=1.0),\n",
    "            ], p=1.0),\n",
    "        ]\n",
    "\n",
    "        return A.OneOf([\n",
    "            A.SomeOf(families, n=1, replace=False, p=1.0),\n",
    "            A.SomeOf(families, n=2, replace=False, p=1.0),\n",
    "        ], p=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c1011",
   "metadata": {
    "id": "f29c1011"
   },
   "outputs": [],
   "source": [
    "# DENORMALIZZAZIONE\n",
    "def denorm(t, mean, std):\n",
    "    # t: torch tensor (C,H,W)\n",
    "    mean = torch.tensor(mean, device=t.device, dtype=t.dtype).view(-1, 1, 1)\n",
    "    std  = torch.tensor(std,  device=t.device, dtype=t.dtype).view(-1, 1, 1)\n",
    "    return t * std + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e3c243",
   "metadata": {
    "id": "47e3c243",
    "outputId": "23d8c54e-44ea-4be7-d45f-30d7c7455f37"
   },
   "outputs": [],
   "source": [
    "train_ratio = 0.70\n",
    "test_ratio = 0.30\n",
    "\n",
    "# Primo split: train vs (val+test)\n",
    "df_train, df_temp = train_test_split(\n",
    "    df,\n",
    "    test_size=test_ratio,\n",
    "    random_state=SEED,\n",
    "    stratify=df[\"label\"] # Mantiene distribuzione classi\n",
    ")\n",
    "\n",
    "# Secondo split: temp (30%) -> val (15%) + test (15%)\n",
    "val_ratio_inside_temp = 0.5  # 50% di df_temp\n",
    "\n",
    "df_val, df_test = train_test_split(\n",
    "    df_temp,\n",
    "    test_size=val_ratio_inside_temp,\n",
    "    random_state=SEED,\n",
    "    stratify=df_temp[\"label\"]\n",
    ")\n",
    "\n",
    "print(\"Train:\", len(df_train))\n",
    "print(\"Val:\", len(df_val))\n",
    "print(\"Test:\", len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13cda47",
   "metadata": {
    "id": "b13cda47"
   },
   "source": [
    "Il dataset totale contiene 62 immagini, suddivise così:\n",
    "\n",
    "- Train: 43 immagini.\n",
    "- Validation: 9 immagini.\n",
    "- Test: 10 immagini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5236b4",
   "metadata": {
    "id": "6c5236b4",
    "outputId": "c3c09fa1-7bf5-4e9d-c099-b235658aa093"
   },
   "outputs": [],
   "source": [
    "# mean/std\n",
    "mean, std = compute_mean_std(df_train, img_dir, img_size=224)\n",
    "\n",
    "# dataset\n",
    "train_ds = CustomDataset(df_train, img_dir, img_size=224, is_train=True, augment=True,  resize=True, mean=mean, std=std)\n",
    "val_ds = CustomDataset(df_val, img_dir, img_size=224,is_train=False, augment=False, resize=True, mean=mean, std=std)\n",
    "test_ds = CustomDataset(df_test, img_dir, img_size=224,is_train=False, augment=False, resize=True, mean=mean, std=std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f079ba5",
   "metadata": {
    "id": "9f079ba5"
   },
   "source": [
    "I valori negativi osservati sono successivi alla normalizzazione.\n",
    "Il controllo del range è stato effettuato prima della Normalize, dove le immagini risultano correttamente comprese tra 0 e 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5efbf0",
   "metadata": {
    "id": "2d5efbf0",
    "outputId": "1984a894-8b05-469f-cd31-98cc0f22308e"
   },
   "outputs": [],
   "source": [
    "id_ = train_ds.df.loc[0, \"id\"]\n",
    "path = os.path.join(train_ds.img_dir, f\"img_{id_}.png\")\n",
    "\n",
    "img = cv2.imread(path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "tf_pre = []\n",
    "\n",
    "# pipeline pre-Normalize\n",
    "if train_ds.is_train and train_ds.augment:\n",
    "    tf_pre.append(train_ds._aug()) # Augmentations\n",
    "if train_ds.resize:\n",
    "    tf_pre.append(A.Resize(train_ds.img_size, train_ds.img_size)) # Resize\n",
    "tf_pre.append(A.ToFloat(max_value=255.0)) # [0,1]\n",
    "\n",
    "# Applico la pipeline e ottengo l'immagine preprocessata\n",
    "img_pre = A.Compose(tf_pre)(image=img)[\"image\"]\n",
    "print(\"Prima di applicare Normalize:\")\n",
    "print(img_pre.dtype, img_pre.min(), img_pre.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9a2301",
   "metadata": {
    "id": "cb9a2301"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9966ffc2",
   "metadata": {
    "id": "9966ffc2",
    "outputId": "e0578556-4c01-4c5a-d43b-bbecee028e47"
   },
   "outputs": [],
   "source": [
    "def plot_aug_images_by_class_multi(\n",
    "    dataset,\n",
    "    n_per_class=3,\n",
    "    k=4,\n",
    "    seed=42,\n",
    "    show_id=True,\n",
    "    pick=\"random\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Mosaico per categoria con più immagini per classe.\n",
    "\n",
    "    Righe: 3 classi * n_per_class\n",
    "    Colonne: 1 originale + k augmentazioni\n",
    "    \"\"\"\n",
    "\n",
    "    random.seed(seed)\n",
    "\n",
    "    label_names = {\n",
    "        0: \"not detectable\",\n",
    "        1: \"benign\",\n",
    "        2: \"malignant\"\n",
    "    }\n",
    "\n",
    "    # resize per visualizzazione (NO normalize)\n",
    "    resize_tf = A.Compose([A.Resize(dataset.img_size, dataset.img_size)])\n",
    "\n",
    "    # blocco augmentation\n",
    "    aug_block = dataset._aug_viz() if hasattr(dataset, \"_aug_viz\") else dataset._aug()\n",
    "    aug_tf = A.Compose([aug_block, A.Resize(dataset.img_size, dataset.img_size)])\n",
    "\n",
    "    # wrapper per titoli più leggibili\n",
    "    def wrap(txt, width=18):\n",
    "        return textwrap.fill(txt, width=width)\n",
    "\n",
    "    # scegli immagini per classe\n",
    "    chosen = []  # (label, global_idx)\n",
    "    for lab in [0, 1, 2]:\n",
    "        sub = dataset.df[dataset.df[\"label\"] == lab]\n",
    "        if len(sub) == 0:\n",
    "            raise ValueError(f\"Nessuna immagine trovata per la classe {lab}\")\n",
    "\n",
    "        n_eff = min(n_per_class, len(sub))\n",
    "        if pick == \"first\":\n",
    "            sub_sel = sub.head(n_eff)\n",
    "        else:\n",
    "            sub_sel = sub.sample(n=n_eff, random_state=seed)\n",
    "\n",
    "        for gi in sub_sel.index.tolist():\n",
    "            chosen.append((lab, gi))\n",
    "\n",
    "    n_rows = len(chosen)\n",
    "    n_cols = k + 1\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        n_rows, n_cols,\n",
    "        figsize=(3.1 * n_cols, 2.9 * n_rows),\n",
    "        constrained_layout=False\n",
    "    )\n",
    "\n",
    "    fig.subplots_adjust(top=0.88, hspace=0.25, wspace=0.05)\n",
    "\n",
    "    fig.suptitle(\n",
    "        f\"Data Augmentation per categoria\\n\",\n",
    "        fontsize=15\n",
    "    )\n",
    "\n",
    "    if n_rows == 1:\n",
    "        axes = np.expand_dims(axes, axis=0)\n",
    "\n",
    "    for r, (lab, global_idx) in enumerate(chosen):\n",
    "        id_ = dataset.df.loc[global_idx, \"id\"]\n",
    "        path = os.path.join(dataset.img_dir, f\"img_{id_}.png\")\n",
    "\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Not found: {path}\")\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        orig = resize_tf(image=img)[\"image\"]\n",
    "\n",
    "        # ---- ORIGINALE ----\n",
    "        title_orig = f\"{label_names[lab]} Originale\"\n",
    "\n",
    "        axes[r, 0].imshow(orig)\n",
    "        axes[r, 0].axis(\"off\")\n",
    "        axes[r, 0].set_title(wrap(title_orig), fontsize=10)\n",
    "\n",
    "        # ---- AUGMENTAZIONI ----\n",
    "        for c in range(1, n_cols):\n",
    "            augm = aug_tf(image=img)[\"image\"]\n",
    "            axes[r, c].imshow(augm)\n",
    "            axes[r, c].axis(\"off\")\n",
    "            axes[r, c].set_title(wrap(f\"Augmentazione {c}\"), fontsize=9)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_aug_images_by_class_multi(\n",
    "    train_ds,\n",
    "    n_per_class=1,\n",
    "    k=4,\n",
    "    seed=42,\n",
    "    show_id=True,\n",
    "    pick=\"random\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93b2f8b",
   "metadata": {
    "id": "f93b2f8b",
    "outputId": "6f2c466a-8ee5-4f0c-88b3-876bd48d5128"
   },
   "outputs": [],
   "source": [
    "# Catalogo augmentation\n",
    "def build_aug_catalog():\n",
    "    \"\"\"\n",
    "    Ritorna lista di (nome, transform) da applicare SINGOLARMENTE.\n",
    "    Niente Normalize/ToTensor: serve per VISUALIZZARE.\n",
    "    \"\"\"\n",
    "    catalog = []\n",
    "\n",
    "    # --- NOISE ---\n",
    "    catalog += [\n",
    "        (\"GaussNoise\", A.GaussNoise(var_limit=(5.0, 35.0), p=1.0)),\n",
    "        (\"MultiplicativeNoise\", A.MultiplicativeNoise(multiplier=(0.85, 1.15), per_channel=True, p=1.0)),\n",
    "        (\"ISONoise\", A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5), p=1.0)),\n",
    "    ]\n",
    "\n",
    "    # --- FLIP / ROT ---\n",
    "    catalog += [\n",
    "        (\"HorizontalFlip\", A.HorizontalFlip(p=1.0)),\n",
    "        (\"VerticalFlip\", A.VerticalFlip(p=1.0)),\n",
    "        (\"RandomRotate90\", A.RandomRotate90(p=1.0)),\n",
    "    ]\n",
    "\n",
    "    # --- COLOR/CONTRAST ---\n",
    "    catalog += [\n",
    "        (\"BrightnessContrast\", A.RandomBrightnessContrast(0.15, 0.15, p=1.0)),\n",
    "        (\"RandomGamma\", A.RandomGamma(gamma_limit=(80, 120), p=1.0)),\n",
    "        (\"CLAHE\", A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=1.0)),\n",
    "    ]\n",
    "\n",
    "    # --- BLUR / SHARPEN ---\n",
    "    catalog += [\n",
    "        (\"GaussianBlur\", A.GaussianBlur(blur_limit=(3, 7), p=1.0)),\n",
    "        (\"MotionBlur\", A.MotionBlur(blur_limit=5, p=1.0)),\n",
    "        (\"Sharpen\", A.Sharpen(alpha=(0.1, 0.35), lightness=(0.9, 1.1), p=1.0)),\n",
    "    ]\n",
    "\n",
    "    # --- GEOMETRIC ---\n",
    "    catalog += [\n",
    "        (\"Rotate15\", A.Rotate(limit=15, border_mode=cv2.BORDER_CONSTANT, p=1.0)),\n",
    "        (\"ShiftScaleRotate\", A.ShiftScaleRotate(\n",
    "            shift_limit=0.04, scale_limit=0.06, rotate_limit=0,\n",
    "            border_mode=cv2.BORDER_CONSTANT, p=1.0\n",
    "        )),\n",
    "        (\"GridDistortion\", A.GridDistortion(num_steps=5, distort_limit=0.2, p=1.0)),\n",
    "    ]\n",
    "\n",
    "    # --- DROPOUT ---\n",
    "    catalog += [\n",
    "        (\"CoarseDropout\", A.CoarseDropout(max_holes=8, max_height=24, max_width=24, fill_value=0, p=1.0)),\n",
    "    ]\n",
    "\n",
    "    return catalog\n",
    "\n",
    "\n",
    "# Prende un immagine da CustomDataset\n",
    "def get_rgb_images_from_dataset(dataset, n_images=2, seed=42, pick=\"random\"):\n",
    "    \"\"\"\n",
    "    ritorna lista di immagini RGB uint8 lette da cv2.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "\n",
    "    n_images = min(n_images, len(dataset))\n",
    "    if n_images <= 0:\n",
    "        raise ValueError(\"Dataset vuoto.\")\n",
    "\n",
    "    if pick == \"first\":\n",
    "        idxs = list(range(n_images))\n",
    "    else:\n",
    "        idxs = random.sample(range(len(dataset)), k=n_images)\n",
    "\n",
    "    imgs = []\n",
    "    ids = []\n",
    "    for idx in idxs:\n",
    "        id_ = dataset.df.loc[idx, \"id\"]\n",
    "        path = os.path.join(dataset.img_dir, f\"img_{id_}.png\")\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Not found: {path}\")\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        imgs.append(img)\n",
    "        ids.append(id_)\n",
    "    return imgs, ids\n",
    "\n",
    "\n",
    "def _wrap(s, width=16):\n",
    "    return \"\\n\".join(textwrap.wrap(str(s), width=width))\n",
    "\n",
    "\n",
    "# Mosaico: originale + tutte le augmentation (1 per tipo)\n",
    "def mosaic_all_augs_for_images(\n",
    "    images_rgb,\n",
    "    ids=None,\n",
    "    img_size=224,\n",
    "    seed=42,\n",
    "    n_cols=5,\n",
    "    title_prefix=\"\",\n",
    "    save_dir=None,\n",
    "    dpi=300,\n",
    "    highlight_original=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Per ogni immagine crea una figura con mosaico:\n",
    "    - 1 tile Originale\n",
    "    - 1 tile per ogni augmentation nel catalogo (una per tipo)\n",
    "    \"\"\"\n",
    "    catalog = build_aug_catalog()\n",
    "    resize_tf = A.Compose([A.Resize(img_size, img_size)])\n",
    "\n",
    "    if save_dir is not None:\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    for i, img in enumerate(images_rgb):\n",
    "        if img.dtype != np.uint8:\n",
    "            img = img.astype(np.uint8)\n",
    "\n",
    "        orig = resize_tf(image=img)[\"image\"]\n",
    "\n",
    "        variants = [(\"Original (baseline)\", orig)]\n",
    "        for j, (name, tform) in enumerate(catalog):\n",
    "            # seed riproducibile per ogni tile\n",
    "            np.random.seed(seed + j)\n",
    "\n",
    "            aug_tf = A.Compose([tform, A.Resize(img_size, img_size)])\n",
    "            aug = aug_tf(image=img)[\"image\"]\n",
    "            variants.append((name, aug))\n",
    "\n",
    "        n = len(variants)\n",
    "        n_rows = math.ceil(n / n_cols)\n",
    "\n",
    "        fig = plt.figure(figsize=(3.0 * n_cols, 3.0 * n_rows))\n",
    "        gs = fig.add_gridspec(n_rows, n_cols, wspace=0.03, hspace=0.18)\n",
    "\n",
    "        # Titolo + sottotitolo\n",
    "        id_txt = f\" | id={ids[i]}\" if ids is not None and i < len(ids) else \"\"\n",
    "        fig.suptitle(\n",
    "            f\"{title_prefix}Augmentation catalog — image #{i+1}{id_txt}\",\n",
    "            fontsize=16, y=0.98\n",
    "        )\n",
    "        fig.text(\n",
    "            0.5, 0.95,\n",
    "            f\"Original + {len(catalog)} transforms | img_size={img_size} | seed={seed}\",\n",
    "            ha=\"center\", va=\"center\", fontsize=11\n",
    "        )\n",
    "\n",
    "        for idx in range(n_rows * n_cols):\n",
    "            r, c = divmod(idx, n_cols)\n",
    "            ax = fig.add_subplot(gs[r, c])\n",
    "            ax.set_xticks([]); ax.set_yticks([])\n",
    "            ax.set_facecolor(\"white\")\n",
    "\n",
    "            # bordo sottile uniforme\n",
    "            for sp in ax.spines.values():\n",
    "                sp.set_visible(True)\n",
    "                sp.set_linewidth(0.6)\n",
    "\n",
    "            if idx < n:\n",
    "                name, im = variants[idx]\n",
    "                ax.imshow(im)\n",
    "                ax.set_title(_wrap(name, width=16), fontsize=10, pad=6)\n",
    "\n",
    "                # evidenzia originale\n",
    "                if highlight_original and idx == 0:\n",
    "                    for sp in ax.spines.values():\n",
    "                        sp.set_linewidth(1.4)\n",
    "            else:\n",
    "                ax.axis(\"off\")\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.92])\n",
    "\n",
    "        if save_dir is not None:\n",
    "            out_path = os.path.join(save_dir, f\"aug_catalog_img{i+1}.png\")\n",
    "            plt.savefig(out_path, dpi=dpi, bbox_inches=\"tight\")\n",
    "            print(\"Salvato:\", out_path)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "imgs, ids = get_rgb_images_from_dataset(train_ds, n_images=1, seed=42, pick=\"random\")\n",
    "mosaic_all_augs_for_images(imgs, ids=ids, img_size=224, seed=42, n_cols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17f0f22",
   "metadata": {
    "id": "d17f0f22"
   },
   "source": [
    "## *Funzioni di pooling*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b74c4f",
   "metadata": {
    "id": "f4b74c4f"
   },
   "source": [
    "### **Max pooling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29794fbc",
   "metadata": {
    "id": "29794fbc"
   },
   "outputs": [],
   "source": [
    "def pool_max(window: torch.Tensor, **kwargs) -> torch.Tensor:\n",
    "    return torch.amax(window, dim=(-1, -2), keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d287d912",
   "metadata": {
    "id": "d287d912"
   },
   "source": [
    "### **Learnable Max - Average Pooling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66da5907",
   "metadata": {
    "id": "66da5907"
   },
   "outputs": [],
   "source": [
    "def pooling_max_avg_2d(patches: torch.Tensor, w: torch.Tensor, g: torch.Tensor, epsilon=1e-8, **kwargs) -> torch.Tensor:\n",
    "\n",
    "    device = patches.device\n",
    "    dtype  = patches.dtype\n",
    "    w   = w.to(device=device, dtype=dtype)\n",
    "    g   = g.to(device=device, dtype=dtype)\n",
    "\n",
    "    # (FIX) accetta w/g sia scalari/1D che 2D (C_eff,K)\n",
    "    if w.dim() == 0:\n",
    "        w = w.view(1, 1)\n",
    "    elif w.dim() == 1:\n",
    "        w = w.view(1, -1)\n",
    "    if g.dim() == 0:\n",
    "        g = g.view(1, 1)\n",
    "    elif g.dim() == 1:\n",
    "        g = g.view(1, -1)\n",
    "    assert w.dim() == 2 and w.size(1) == 2, f\"w must be (C_eff,2), got {tuple(w.shape)}\"\n",
    "    assert g.dim() == 2 and g.size(1) == 1, f\"g must be (C_eff,1) or (1,1), got {tuple(g.shape)}\"\n",
    "\n",
    "    # patches: (B,Ho,Wo,C,kH,kW)\n",
    "    x_max = torch.amax(patches + epsilon, dim=(-1, -2), keepdim=True)   # (B,Ho,Wo,C,1,1)\n",
    "    x_avg = torch.mean(patches + epsilon, dim=(-1, -2), keepdim=True)\n",
    "\n",
    "    w = torch.softmax(w, dim=-1)  # (C_eff,2) con densatio: C_eff=1 se shared_window=True\n",
    "\n",
    "    # canale è in dim=3 -> broadcast su (B,Ho,Wo,C,1,1)\n",
    "    w_max = w[:, 0].view(1, 1, 1, -1, 1, 1)\n",
    "    w_avg = w[:, 1].view(1, 1, 1, -1, 1, 1)\n",
    "\n",
    "    g = torch.sigmoid(g).view(1, 1, 1, -1, 1, 1)\n",
    "\n",
    "    return (w_max * x_max + w_avg * x_avg) * g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b0b0c2",
   "metadata": {
    "id": "79b0b0c2"
   },
   "source": [
    "### **Stochastic pooling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7405e3ab",
   "metadata": {
    "id": "7405e3ab"
   },
   "outputs": [],
   "source": [
    "def stochastic_pooling2d(patches: torch.Tensor, eps=1e-8, **kwargs) -> torch.Tensor:\n",
    "    B, Ho, Wo, C, kH, kW = patches.shape\n",
    "    K = kH * kW\n",
    "\n",
    "    x_flat = patches.reshape(B * Ho * Wo * C, K)\n",
    "    probs = F.softmax(x_flat, dim=-1) + eps\n",
    "\n",
    "    idx = torch.multinomial(probs, 1)               # (N,1)\n",
    "    sampled = x_flat.gather(1, idx).squeeze(1)      # (N,)\n",
    "\n",
    "    return sampled.view(B, Ho, Wo, C, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4279c0",
   "metadata": {
    "id": "5d4279c0"
   },
   "source": [
    "### **Weighted Max Pooling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1209f275",
   "metadata": {
    "id": "1209f275"
   },
   "outputs": [],
   "source": [
    "def weighted_max_pooling(patches, e_exponent, epsilon=1e-4, **kwargs):\n",
    "    # x: (B, Ho, Wo, C, kH, kW)  -> out: (B, Ho, Wo, C, 1, 1)\n",
    "    device = patches.device\n",
    "    dtype  = patches.dtype\n",
    "    e_exponent= e_exponent.to(device=device, dtype=dtype)\n",
    "\n",
    "    e_exp = e_exponent.view(1, 1, 1, -1, 1, 1)  # broadcast su C (densatio: canali in dim=3)\n",
    "    x_safe = torch.clamp(patches + epsilon, min=epsilon)\n",
    "\n",
    "    out = torch.max(\n",
    "        torch.max(torch.pow(x_safe, e_exp), dim=-1, keepdim=True)[0],\n",
    "        dim=-2, keepdim=True\n",
    "    )[0]  # (B,Ho,Wo,C,1,1)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb7c5cc",
   "metadata": {
    "id": "fdb7c5cc"
   },
   "source": [
    "### **Log-Sum-Exp pooling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad32c2c",
   "metadata": {
    "id": "bad32c2c"
   },
   "outputs": [],
   "source": [
    "def lse_pooling2d(patches: torch.Tensor, beta: torch.Tensor, g: torch.Tensor, eps=1e-12, **kwargs) -> torch.Tensor:\n",
    "    device = patches.device\n",
    "    dtype  = patches.dtype\n",
    "    beta= beta.to(device=device, dtype=dtype)\n",
    "    g= g.to(device=device, dtype=dtype)\n",
    "\n",
    "    B, Ho, Wo, C, kH, kW = patches.shape\n",
    "    K = kH * kW\n",
    "    x = patches.reshape(B, Ho, Wo, C, K)\n",
    "\n",
    "    beta_eff = (F.softplus(beta) + eps).view(1, 1, 1, -1, 1)\n",
    "    g_eff = torch.sigmoid(g).view(1, 1, 1, -1, 1)\n",
    "\n",
    "    m = torch.max(x, dim=-1, keepdim=True)[0]\n",
    "    z = beta_eff * (x - m)\n",
    "    out = m + (1.0 / beta_eff) * torch.log(torch.mean(torch.exp(z), dim=-1, keepdim=True) + eps)\n",
    "\n",
    "    out = out * (1.0 + g_eff)    # (B,Ho,Wo,C,1)\n",
    "    return out.unsqueeze(-1)     # (B,Ho,Wo,C,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffce35f2",
   "metadata": {
    "id": "ffce35f2"
   },
   "source": [
    "### **GeM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fe4783",
   "metadata": {
    "id": "c4fe4783"
   },
   "outputs": [],
   "source": [
    "def gem_pooling2d(patches, p, eps=1e-6, **kwargs):\n",
    "    \"\"\"\n",
    "    GeM pooling (Generalized Mean) per finestra.\n",
    "    patches: (B, Ho, Wo, C, kH, kW)\n",
    "    p: tensor broadcastabile su C (es. shape (1,1) oppure (C,1))\n",
    "    return: (B, Ho, Wo, C, 1, 1)\n",
    "    \"\"\"\n",
    "    device = patches.device\n",
    "    dtype  = patches.dtype\n",
    "    p= p.to(device=device, dtype=dtype)\n",
    "\n",
    "    # p >= 1 (stabile): p_eff = 1 + softplus(p)\n",
    "    p_eff = 1.0 + F.softplus(p)\n",
    "\n",
    "    # broadcast su (B,Ho,Wo,C,1,1)\n",
    "    p_eff = p_eff.view(1, 1, 1, -1, 1, 1)\n",
    "\n",
    "    x = torch.clamp(patches, min=0.0) + eps\n",
    "    # mean(x^p)^(1/p) su kH,kW\n",
    "    out = torch.mean(x ** p_eff, dim=(-1, -2), keepdim=True) ** (1.0 / p_eff)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72634422",
   "metadata": {
    "id": "72634422"
   },
   "source": [
    "### **Adaptive Statical Pooling (LSE - GeM - Std)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e0676a",
   "metadata": {
    "id": "50e0676a"
   },
   "outputs": [],
   "source": [
    "def adp_stat_pooling2d(patches, w, tau, p, g, eps=1e-6, **kwargs):\n",
    "    \"\"\"\n",
    "    patches: (B, Ho, Wo, C, kH, kW)\n",
    "    ritorna: (B, Ho, Wo, C, 1, 1)\n",
    "\n",
    "    Supporta:\n",
    "      - w shape (3,)      -> shared-channel\n",
    "      - w shape (1,3)     -> shared-channel\n",
    "      - w shape (C,3)     -> per-canale\n",
    "    \"\"\"\n",
    "    device = patches.device\n",
    "    dtype  = patches.dtype\n",
    "\n",
    "    w   = w.to(device=device, dtype=dtype)\n",
    "    tau = tau.to(device=device, dtype=dtype)\n",
    "    p   = p.to(device=device, dtype=dtype)\n",
    "    g   = g.to(device=device, dtype=dtype)\n",
    "\n",
    "    B, Ho, Wo, C, kH, kW = patches.shape\n",
    "    K = kH * kW\n",
    "\n",
    "    x = patches.reshape(B, Ho, Wo, C, K)\n",
    "    x = torch.clamp(x, min=0.0) + eps\n",
    "\n",
    "    #  parametri scalari / per-canale (broadcast safe)\n",
    "    tau_eff = (F.softplus(tau) + eps).view(1, 1, 1, -1, 1)\n",
    "    p_eff   = (1.0 + F.softplus(p)).view(1, 1, 1, -1, 1)\n",
    "    g_eff   = (1.0 + torch.sigmoid(g)).view(1, 1, 1, -1, 1)\n",
    "\n",
    "    # ---- LSE\n",
    "    z = x / tau_eff\n",
    "    z = z - torch.max(z, dim=-1, keepdim=True)[0]\n",
    "    lse = tau_eff * torch.log(torch.mean(torch.exp(z), dim=-1, keepdim=True) + eps)\n",
    "\n",
    "    # ---- GeM\n",
    "    gem = torch.mean(x ** p_eff, dim=-1, keepdim=True) ** (1.0 / p_eff)\n",
    "\n",
    "    # ---- Std\n",
    "    std = torch.sqrt(torch.var(x, dim=-1, keepdim=True, unbiased=False) + eps)\n",
    "\n",
    "    # w: (3,) | (1,3) | (C,3)\n",
    "    if w.dim() == 1:\n",
    "        # (3,) -> (1,3) -> (C,3)\n",
    "        w = w.view(1, 3).expand(C, 3)\n",
    "    elif w.dim() == 2 and w.shape[0] == 1:\n",
    "        # (1,3) -> (C,3)\n",
    "        w = w.expand(C, 3)\n",
    "    elif w.dim() == 2 and w.shape[0] == C:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(f\"w ha shape non supportata: {w.shape}\")\n",
    "\n",
    "    w_mix = torch.softmax(w, dim=-1)  # (C,3)\n",
    "\n",
    "    w_lse = w_mix[:, 0].view(1, 1, 1, C, 1)\n",
    "    w_gem = w_mix[:, 1].view(1, 1, 1, C, 1)\n",
    "    w_std = w_mix[:, 2].view(1, 1, 1, C, 1)\n",
    "\n",
    "    out = (w_lse * lse + w_gem * gem + w_std * std) * g_eff\n",
    "    return out.unsqueeze(-1)  # (B,Ho,Wo,C,1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d237345",
   "metadata": {
    "id": "7d237345"
   },
   "source": [
    "## *ResNet*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938fa9b9",
   "metadata": {
    "id": "938fa9b9"
   },
   "outputs": [],
   "source": [
    "POOLING_MAP = {\n",
    "    \"max\": (pool_max, {}),\n",
    "\n",
    "    \"stochastic\": (stochastic_pooling2d, {}),\n",
    "\n",
    "    \"maxavg\": (\n",
    "        pooling_max_avg_2d,\n",
    "        {\n",
    "            \"w\": {\"init_value\": torch.ones(1, 2) * 0.5, \"requires_grad\": True},\n",
    "            \"g\": {\"init_value\": torch.ones(1) * 0.5, \"requires_grad\": True},\n",
    "        }\n",
    "    ),\n",
    "\n",
    "    \"weighted_max_pooling\": (weighted_max_pooling,\n",
    "    {\n",
    "        \"e_exponent\": {\n",
    "            \"init_value\": torch.ones(1) * 1.5,   # es. 1.0=quasi max, >1 più aggressivo\n",
    "            \"requires_grad\": True\n",
    "        }\n",
    "    }\n",
    "),\n",
    "\n",
    "    \"lse\": (\n",
    "        lse_pooling2d,\n",
    "        {\n",
    "            \"beta\": {\"init_value\": torch.ones(1) * 0.5, \"requires_grad\": True},\n",
    "            \"g\":    {\"init_value\": torch.ones(1) * 0.5, \"requires_grad\": True},\n",
    "        }\n",
    "    ),\n",
    "\n",
    "    \"gem\": (\n",
    "        gem_pooling2d,\n",
    "        {\n",
    "            \"p\": {\"init_value\": torch.ones(1) * 0.5, \"requires_grad\": True},  # p_eff ≈ 1.97\n",
    "        }\n",
    "    ),\n",
    "\n",
    "    \"adpstat\": (\n",
    "        adp_stat_pooling2d,\n",
    "        {\n",
    "            \"w\":   {\"init_value\": torch.ones(3) * 0.5, \"requires_grad\": True},\n",
    "            \"tau\": {\"init_value\": torch.ones(1) * 0.5, \"requires_grad\": True},\n",
    "            \"p\":   {\"init_value\": torch.ones(1) * 0.5, \"requires_grad\": True},\n",
    "            \"g\":   {\"init_value\": torch.ones(1) * 0.5, \"requires_grad\": True},\n",
    "        }\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ec48cc",
   "metadata": {
    "id": "78ec48cc"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, 3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, 3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        return F.relu(out + identity, inplace=True)\n",
    "\n",
    "\n",
    "def _make_layer(in_planes, planes, blocks, stride):\n",
    "    downsample = None\n",
    "    if stride != 1 or in_planes != planes:\n",
    "        downsample = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, planes, 1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(planes),\n",
    "        )\n",
    "    layers = [BasicBlock(in_planes, planes, stride=stride, downsample=downsample)]\n",
    "    for _ in range(1, blocks):\n",
    "        layers.append(BasicBlock(planes, planes))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"ResNet50/101/152\"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        super().__init__()\n",
    "        width = out_channels\n",
    "        out_expanded = out_channels * self.expansion\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, width, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(width)\n",
    "\n",
    "        # stride NON esposto: sempre 1\n",
    "        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(width)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(width, out_expanded, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_expanded)\n",
    "\n",
    "\n",
    "        if in_channels == out_expanded:\n",
    "            self.skip = nn.Identity()\n",
    "        else:\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_expanded, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(out_expanded),\n",
    "            )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        out = out + self.skip(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes=3,\n",
    "        pooling_choice=\"max\",      # chiave in POOLING_MAP\n",
    "        stem_pool_size=(3, 3),\n",
    "        stem_stride=(2, 2),\n",
    "        stem_padding=\"same\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # pooling\n",
    "        if isinstance(pooling_choice, str):\n",
    "            if pooling_choice not in POOLING_MAP:\n",
    "                raise ValueError(f\"pooling_choice sconosciuta: {pooling_choice}. Valide: {list(POOLING_MAP.keys())}\")\n",
    "\n",
    "            entry = POOLING_MAP[pooling_choice]\n",
    "\n",
    "            if isinstance(entry, tuple):\n",
    "                self.pooling_method, self.pooling_params_base = entry\n",
    "                self.pooling_params_base = copy.deepcopy(self.pooling_params_base)\n",
    "            else:\n",
    "                self.pooling_method = entry\n",
    "                self.pooling_params_base = {}\n",
    "        else:\n",
    "            self.pooling_method = pooling_choice\n",
    "            self.pooling_params_base = {}\n",
    "\n",
    "        # stem ResNet\n",
    "        self.conv1 = nn.Conv2d(3, 64, 7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "\n",
    "        # layers ResNet18\n",
    "        self.layer1 = _make_layer(64,  64, 2, 1)\n",
    "        self.layer2 = _make_layer(64,  128, 2, 2)\n",
    "        self.layer3 = _make_layer(128, 256, 2, 2)\n",
    "        self.layer4 = _make_layer(256, 512, 2, 2)\n",
    "\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "        # densatio pool\n",
    "        self._dense_pool = None\n",
    "        self._pool_sig = None\n",
    "\n",
    "        # config pooling\n",
    "        self._stem_pool_size = stem_pool_size\n",
    "        self._stem_stride = stem_stride\n",
    "        self._stem_padding = stem_padding\n",
    "\n",
    "    def _build_pool(self):\n",
    "        return CustomPooling2d(\n",
    "            pool_size=self._stem_pool_size,\n",
    "            stride=self._stem_stride,\n",
    "            padding=self._stem_padding,\n",
    "            pooling_method=self.pooling_method,\n",
    "            pooling_params=self.pooling_params_base,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(self.relu(self.bn1(self.conv1(x))))\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)  # (B,512,H,W)\n",
    "\n",
    "        # GLOBAL POOLING: finestra = (H,W) per ottenere (B,512,1,1)\n",
    "        H, W = x.shape[-2], x.shape[-1]\n",
    "\n",
    "        sig = (x.device.type, x.dtype, H, W, self.pooling_method.__name__)\n",
    "        if self._dense_pool is None or getattr(self, \"_pool_sig\", None) != sig:\n",
    "            self._stem_pool_size = (H, W)\n",
    "            self._stem_stride = (1, 1)\n",
    "            self._stem_padding = \"valid\"\n",
    "            self._dense_pool = self._build_pool()\n",
    "            self._pool_sig = sig\n",
    "\n",
    "        x = self._dense_pool(x)           # (B,512,1,1)\n",
    "        x = torch.flatten(x, 1)           # (B,512)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c552ca2e",
   "metadata": {
    "id": "c552ca2e",
    "outputId": "c4e40a38-fef1-40f3-c456-7082a58d921b"
   },
   "outputs": [],
   "source": [
    "model = ResNet18(num_classes=NUM_CLASSES, pooling_choice=\"max\").to(device)\n",
    "\n",
    "for key in POOLING_MAP.keys():\n",
    "    model = ResNet18(num_classes=NUM_CLASSES, pooling_choice=key).to(device)\n",
    "    print(\"Training with pooling:\", key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5514255b",
   "metadata": {
    "id": "5514255b"
   },
   "source": [
    "## *Ciclo di addestramento*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7869bfdb",
   "metadata": {
    "id": "7869bfdb"
   },
   "outputs": [],
   "source": [
    "def clean():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "def ensure_dir(path: str):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def save_cm_csv(cm, out_path: str):\n",
    "    pd.DataFrame(cm.numpy()).to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bda85f7",
   "metadata": {
    "id": "2bda85f7"
   },
   "outputs": [],
   "source": [
    "RESULTS_DIR = \"results\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3553ec16",
   "metadata": {
    "id": "3553ec16"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 3\n",
    "NUM_EPOCHS = 250\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "RESIZES = [False, True]\n",
    "CHANNELS = [False, True]\n",
    "AUGS = [False, True]\n",
    "POOLINGS = list(POOLING_MAP.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c78a069",
   "metadata": {
    "id": "7c78a069"
   },
   "outputs": [],
   "source": [
    "def cm_metrics(model, loader, num_classes=3):\n",
    "    model.eval()\n",
    "\n",
    "    cm_metric = MulticlassConfusionMatrix(num_classes=num_classes).to(device)\n",
    "    acc_metric = MulticlassAccuracy(num_classes=num_classes, average=\"micro\").to(device)\n",
    "    bal_metric = MulticlassAccuracy(num_classes=num_classes, average=\"macro\").to(device)\n",
    "    wacc_metric = MulticlassAccuracy(num_classes=num_classes, average=\"weighted\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(loader, desc=\"test\", leave=False):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            preds = logits.argmax(dim=1)\n",
    "\n",
    "            cm_metric.update(preds, y)\n",
    "            acc_metric.update(preds, y)\n",
    "            bal_metric.update(preds, y)\n",
    "            wacc_metric.update(preds, y)\n",
    "\n",
    "    cm = cm_metric.compute().cpu()\n",
    "    acc = acc_metric.compute().item()\n",
    "    bal = bal_metric.compute().item()\n",
    "    wacc = wacc_metric.compute().item()\n",
    "\n",
    "    return cm, acc, bal, wacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be390230",
   "metadata": {
    "id": "be390230"
   },
   "outputs": [],
   "source": [
    "def train_val_bestloss(model, train_loader, val_loader, NUM_EPOCHS: int, NUM_CLASSES: int, out_dir=None):\n",
    "    \"\"\"\n",
    "    Allena NUM_EPOCHS epoche e seleziona best model su MIN val loss.\n",
    "    Salva history.csv + best_model.pt se out_dir è fornita.\n",
    "    Ritorna:\n",
    "      - history: list di dict\n",
    "      - best_val: dict con best_epoch e best_val_loss\n",
    "    \"\"\"\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_w = copy.deepcopy(model.state_dict())\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_epoch = 0\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        for phase, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            tot = 0\n",
    "            loss_sum = 0.0\n",
    "\n",
    "            for x, y in tqdm(loader, desc=f\"{phase} e{epoch+1}\", leave=False):\n",
    "                x = x.to(device, non_blocking=True)\n",
    "                y = y.to(device, non_blocking=True)\n",
    "\n",
    "                if phase == \"train\":\n",
    "                    opt.zero_grad(set_to_none=True)\n",
    "\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    out = model(x)\n",
    "                    loss = crit(out, y)\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        opt.step()\n",
    "\n",
    "                bs = y.size(0)\n",
    "                tot += bs\n",
    "                loss_sum += loss.item() * bs\n",
    "\n",
    "            avg_loss = loss_sum / max(tot, 1)\n",
    "            history.append({\"epoch\": epoch + 1, \"phase\": phase, \"loss\": float(avg_loss)})\n",
    "\n",
    "            print(f\"epoch {epoch+1}/{NUM_EPOCHS} | {phase} | loss {avg_loss:.6f}\")\n",
    "\n",
    "            if phase == \"val\" and avg_loss < best_val_loss:\n",
    "                best_val_loss = float(avg_loss)\n",
    "                best_epoch = epoch + 1\n",
    "                best_w = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        # se hai una tua funzione clean() nel notebook, chiamala pure fuori da qui\n",
    "\n",
    "    best_val = {\"best_epoch\": int(best_epoch), \"best_val_loss\": float(best_val_loss)}\n",
    "\n",
    "    if out_dir is not None:\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        pd.DataFrame(history).to_csv(os.path.join(out_dir, \"history.csv\"), index=False)\n",
    "        torch.save(best_w, os.path.join(out_dir, \"best_model.pt\"))\n",
    "\n",
    "    return history, best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c74cc0",
   "metadata": {
    "id": "14c74cc0"
   },
   "outputs": [],
   "source": [
    "RESULTS_GRID = \"results_bestvalloss\"\n",
    "\n",
    "def run_grid_resize_channels_aug_poolings(\n",
    "    RESIZES, CHANNELS, AUGS, POOLINGS,\n",
    "    POOLING_MAP,\n",
    "    CustomDataset,\n",
    "    df_train, df_val, df_test,\n",
    "    img_dir, mean, std,\n",
    "    BATCH_SIZE: int,\n",
    "    NUM_EPOCHS: int,\n",
    "    NUM_CLASSES: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Per ogni combinazione:\n",
    "      resize ∈ {T,F}\n",
    "      shared_window_across_channels ∈ {T,F}\n",
    "      augment_train ∈ {T,F}\n",
    "      pooling ∈ POOLINGS\n",
    "\n",
    "    best model su MIN val loss, poi test.\n",
    "    \"\"\"\n",
    "    ensure_dir(RESULTS_GRID)\n",
    "    rows = []\n",
    "\n",
    "    POOLINGS = list(POOLING_MAP.keys())\n",
    "\n",
    "    for resize in RESIZES:\n",
    "        rdir = os.path.join(RESULTS_GRID, f\"resize_{int(resize)}\")\n",
    "        ensure_dir(rdir)\n",
    "\n",
    "        for ch in CHANNELS:\n",
    "            cdir = os.path.join(rdir, f\"channels_{int(ch)}\")\n",
    "            ensure_dir(cdir)\n",
    "\n",
    "            for pooling in tqdm(POOLINGS, desc=f\"poolings | resize={int(resize)} ch={int(ch)}\", leave=False):\n",
    "                if pooling not in POOLING_MAP:\n",
    "                    print(f\"[SKIP] pooling='{pooling}' non trovato in POOLING_MAP.\")\n",
    "                    continue\n",
    "\n",
    "                pool_params = POOLING_MAP[pooling][1]\n",
    "\n",
    "                pdir = os.path.join(cdir, f\"pooling_{pooling}\")\n",
    "                ensure_dir(pdir)\n",
    "\n",
    "                for aug in AUGS:\n",
    "                    adir = os.path.join(pdir, f\"aug_{int(aug)}\")\n",
    "                    ensure_dir(adir)\n",
    "\n",
    "                    print(f\"\\n>>> START resize={resize} shared_channels={ch} pooling={pooling} aug={aug} | path={adir}\")\n",
    "\n",
    "                    # DATASETS / LOADERS\n",
    "                    train_ds = CustomDataset(df_train, img_dir, img_size=224, is_train=True,\n",
    "                                             augment=bool(aug), resize=bool(resize), mean=mean, std=std)\n",
    "                    val_ds   = CustomDataset(df_val, img_dir, img_size=224, is_train=False,\n",
    "                                             augment=False, resize=bool(resize), mean=mean, std=std)\n",
    "                    test_ds  = CustomDataset(df_test, img_dir, img_size=224, is_train=False,\n",
    "                                             augment=False, resize=bool(resize), mean=mean, std=std)\n",
    "\n",
    "                    tr_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "                    va_loader = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False)\n",
    "                    te_loader = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "                    # MODEL (TRAIN)\n",
    "                    pool_choice = pooling\n",
    "\n",
    "                    if pool_choice == \"max\":\n",
    "                        stem_pool_size = (3, 3)   # oppure (5,5)\n",
    "                    else:\n",
    "                        stem_pool_size = (2, 2)\n",
    "\n",
    "                    model = ResNet18(\n",
    "                        num_classes=NUM_CLASSES,\n",
    "                        pooling_choice=pool_choice,\n",
    "                        stem_pool_size=stem_pool_size,\n",
    "                        stem_stride=(2, 2),\n",
    "                        stem_padding=\"same\",\n",
    "                    ).to(device)\n",
    "\n",
    "                    # TRAIN/VAL\n",
    "                    history, best_val = train_val_bestloss(\n",
    "                        model, tr_loader, va_loader,\n",
    "                        NUM_EPOCHS=NUM_EPOCHS,\n",
    "                        NUM_CLASSES=NUM_CLASSES,\n",
    "                        out_dir=adir\n",
    "                    )\n",
    "\n",
    "                    # libera RAM\n",
    "                    del model\n",
    "                    clean()\n",
    "\n",
    "                    # MODEL (TEST) ricarico best\n",
    "                    model = ResNet18(\n",
    "                        num_classes=NUM_CLASSES,\n",
    "                        pooling_choice=pool_choice,\n",
    "                        stem_pool_size=stem_pool_size,\n",
    "                        stem_stride=(2, 2),\n",
    "                        stem_padding=\"same\",\n",
    "                    ).to(device)\n",
    "\n",
    "                    best_path = os.path.join(adir, \"best_model.pt\")\n",
    "                    state = torch.load(best_path, map_location=device)\n",
    "                    model.load_state_dict(state,strict=False)\n",
    "                    model.eval()\n",
    "\n",
    "                    # TEST\n",
    "                    cm, acc, bal, wacc = cm_metrics(model, te_loader, num_classes=NUM_CLASSES)\n",
    "                    save_cm_csv(cm, os.path.join(adir, \"cm_test.csv\"))\n",
    "\n",
    "                    rows.append({\n",
    "                        \"resize\": bool(resize),\n",
    "                        \"channels\": bool(ch),\n",
    "                        \"pooling\": str(pooling),\n",
    "                        \"augment_train\": bool(aug),\n",
    "                        \"best_epoch\": int(best_val[\"best_epoch\"]),\n",
    "                        \"best_val_loss\": float(best_val[\"best_val_loss\"]),\n",
    "                        \"test_acc\": float(acc),\n",
    "                        \"test_bal_acc\": float(bal),\n",
    "                        \"test_weighted_acc\": float(wacc),\n",
    "                        \"path\": adir,\n",
    "                    })\n",
    "\n",
    "                    del model\n",
    "                    clean()\n",
    "\n",
    "    out_csv = os.path.join(RESULTS_GRID, \"results_all.csv\")\n",
    "    pd.DataFrame(rows).to_csv(out_csv, index=False)\n",
    "    print(\"Done:\", RESULTS_GRID, \"| saved:\", out_csv)\n",
    "    return out_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8e449a",
   "metadata": {
    "id": "cc8e449a",
    "outputId": "17dc32cc-c783-453f-f556-dce397cd9cf5"
   },
   "outputs": [],
   "source": [
    "def sanity_check_poolings(poolings_to_test, num_classes=2, img_size=224, device=None):\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"device:\", device)\n",
    "\n",
    "    # batch finto\n",
    "    x = torch.randn(2, 3, img_size, img_size, device=device)\n",
    "    y = torch.randint(0, num_classes, (2,), device=device)\n",
    "\n",
    "    ok, bad = [], []\n",
    "\n",
    "    for p in poolings_to_test:\n",
    "        try:\n",
    "            model = ResNet18(\n",
    "                num_classes=num_classes,\n",
    "                pooling_choice=p,\n",
    "                stem_pool_size=(2, 2) if p != \"texture\" else (3, 3),\n",
    "                stem_stride=(2, 2),\n",
    "                stem_padding=\"same\",\n",
    "            ).to(device)\n",
    "\n",
    "            model.train()\n",
    "            out = model(x)\n",
    "            assert out.dim() == 2 and out.shape[0] == x.shape[0] and out.shape[1] == num_classes, \\\n",
    "                f\"Output shape strana: {tuple(out.shape)}\"\n",
    "\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            assert torch.isfinite(loss).item(), \"Loss non finita (NaN/Inf)\"\n",
    "\n",
    "            model.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "\n",
    "            # check gradienti finiti\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.grad is not None and not torch.isfinite(param.grad).all().item():\n",
    "                    raise RuntimeError(f\"Grad non finito in {name}\")\n",
    "\n",
    "            ok.append(p)\n",
    "        except Exception as e:\n",
    "            bad.append((p, repr(e)))\n",
    "        finally:\n",
    "            del model\n",
    "            if device == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"\\nOK:\", ok)\n",
    "    print(\"\\nFAIL:\")\n",
    "    for p, e in bad:\n",
    "        print(\" -\", p, \"->\", e)\n",
    "\n",
    "# poolings da testare: tutti tranne max e stochastic\n",
    "poolings_to_test = [k for k in POOLING_MAP.keys() if k not in (\"max\", \"stochastic\")]\n",
    "sanity_check_poolings(poolings_to_test, num_classes=NUM_CLASSES if \"NUM_CLASSES\" in globals() else 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441ea90d",
   "metadata": {
    "id": "441ea90d",
    "outputId": "c9ccfc3e-e171-42b1-9642-c647102753c9"
   },
   "outputs": [],
   "source": [
    "run_grid_resize_channels_aug_poolings(\n",
    "   RESIZES=RESIZES,\n",
    "    CHANNELS=CHANNELS,\n",
    "    AUGS=AUGS,\n",
    "    POOLINGS=POOLINGS,\n",
    "    POOLING_MAP=POOLING_MAP,\n",
    "    CustomDataset=CustomDataset,\n",
    "    df_train=df_train,\n",
    "    df_val=df_val,\n",
    "    df_test=df_test,\n",
    "    img_dir=img_dir,\n",
    "    mean=mean,\n",
    "    std=std,\n",
    "    BATCH_SIZE=16,\n",
    "    NUM_EPOCHS=250,\n",
    "    NUM_CLASSES=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9505c1cc",
   "metadata": {
    "id": "9505c1cc"
   },
   "source": [
    "## *Risultati*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fc12f8",
   "metadata": {
    "id": "d6fc12f8"
   },
   "source": [
    "### **LOSS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87da811a",
   "metadata": {
    "id": "87da811a"
   },
   "outputs": [],
   "source": [
    "base_dir = \"results_bestvalloss\"\n",
    "res = \"results_all.csv\"\n",
    "path = os.path.join(base_dir, res)\n",
    "results_df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626c3dcb",
   "metadata": {
    "id": "626c3dcb",
    "outputId": "258fa4ad-21b6-4763-f65a-5ccdd61e56ed"
   },
   "outputs": [],
   "source": [
    "EPOCH_COL = \"epoch\"\n",
    "PHASE_COL = \"phase\"   # \"train\"/\"val\"\n",
    "LOSS_COL  = \"loss\"\n",
    "\n",
    "POOLINGS = [\"max\", \"stochastic\", \"maxavg\", \"weighted_max_pooling\", \"lse\", \"gem\", \"adpstat\"]\n",
    "\n",
    "# TRAIN: colore fisso per pooling\n",
    "POOL_COLOR = {\n",
    "    \"max\": \"#1f77b4\",\n",
    "    \"stochastic\": \"#ff7f0e\",\n",
    "    \"maxavg\": \"#2ca02c\",\n",
    "    \"weighted_max_pooling\": \"#efff09\",\n",
    "    \"lse\": \"#f01405\",\n",
    "    \"gem\": \"#35f8ff\",\n",
    "    \"adpstat\": \"#ED80C9\",\n",
    "}\n",
    "\n",
    "# VAL: colore fisso uguale per tutti\n",
    "VAL_COLOR = \"#71067B\"\n",
    "\n",
    "# 4 combinazioni (ordine fisso)\n",
    "COMBOS = [\n",
    "    (True,  True),\n",
    "    (False, False),\n",
    "    (True,  False),\n",
    "    (False, True),\n",
    "]\n",
    "\n",
    "for col in [\"resize\", \"channels\", \"augment_train\"]:\n",
    "    if col in results_df.columns:\n",
    "        results_df[col] = (\n",
    "            results_df[col]\n",
    "            .map({\"True\": True, \"False\": False, \"1\": True, \"0\": False})\n",
    "            .fillna(results_df[col])\n",
    "            .astype(bool)\n",
    "        )\n",
    "\n",
    "required_cols = {\"pooling\", \"path\", \"resize\", \"channels\"}\n",
    "missing_cols = sorted(list(required_cols - set(results_df.columns)))\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Mancano colonne in results_all.csv: {missing_cols}\")\n",
    "\n",
    "present_poolings = set(results_df[\"pooling\"].astype(str).unique())\n",
    "missing_poolings = [p for p in POOLINGS if p not in present_poolings]\n",
    "extra_poolings = sorted(list(present_poolings - set(POOLINGS)))\n",
    "print(\"Pooling mancanti rispetto a POOLINGS:\", missing_poolings)\n",
    "print(\"Pooling extra presenti nel CSV:\", extra_poolings)\n",
    "\n",
    "def resolve_run_dir(p: str) -> str:\n",
    "    p = str(p).strip().replace(\"\\\\\", os.sep).replace(\"/\", os.sep)\n",
    "    if os.path.isabs(p) and os.path.exists(p):\n",
    "        return p\n",
    "    if os.path.exists(p):\n",
    "        return p\n",
    "    return os.path.join(base_dir, p)\n",
    "\n",
    "def load_history(run_dir: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(os.path.join(run_dir, \"history.csv\"))\n",
    "\n",
    "def aggregate_histories(df_subset: pd.DataFrame, phase: str):\n",
    "    \"\"\"Media±std su tutti i run in df_subset per una fase.\"\"\"\n",
    "    series_list = []\n",
    "\n",
    "    for _, row in df_subset.iterrows():\n",
    "        run_dir = resolve_run_dir(row[\"path\"])\n",
    "        if not os.path.exists(run_dir):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            h = load_history(run_dir)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        if not {EPOCH_COL, PHASE_COL, LOSS_COL}.issubset(h.columns):\n",
    "            continue\n",
    "\n",
    "        hh = h[h[PHASE_COL].astype(str).str.lower() == phase.lower()].copy()\n",
    "        if hh.empty:\n",
    "            continue\n",
    "\n",
    "        hh = hh.sort_values(EPOCH_COL)\n",
    "        s = pd.Series(hh[LOSS_COL].values, index=hh[EPOCH_COL].values)\n",
    "        series_list.append(s)\n",
    "\n",
    "    if not series_list:\n",
    "        return None\n",
    "\n",
    "    common_epochs = set(series_list[0].index)\n",
    "    for s in series_list[1:]:\n",
    "        common_epochs &= set(s.index)\n",
    "    if not common_epochs:\n",
    "        return None\n",
    "\n",
    "    common_epochs = np.array(sorted(common_epochs))\n",
    "    mat = np.vstack([s.loc[common_epochs].values for s in series_list])\n",
    "    return common_epochs, mat.mean(axis=0), mat.std(axis=0, ddof=0), mat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8c539f",
   "metadata": {
    "id": "ca8c539f",
    "outputId": "4fa0b8a1-f900-4a1c-bd06-5ed79ed2b6a2"
   },
   "outputs": [],
   "source": [
    "EPOCH_COL = \"epoch\"\n",
    "PHASE_COL = \"phase\"   # \"train\"/\"val\"\n",
    "LOSS_COL  = \"loss\"\n",
    "\n",
    "POOLINGS = [\"max\", \"stochastic\", \"maxavg\", \"weighted_max_pooling\", \"lse\", \"gem\", \"adpstat\"]\n",
    "\n",
    "POOL_COLOR = {\n",
    "    \"max\": \"#1f77b4\",\n",
    "    \"stochastic\": \"#ff7f0e\",\n",
    "    \"maxavg\": \"#2ca02c\",\n",
    "    \"weighted_max_pooling\": \"#efff09\",\n",
    "    \"lse\": \"#f01405\",\n",
    "    \"gem\": \"#35f8ff\",\n",
    "    \"adpstat\": \"#ED80C9\",\n",
    "}\n",
    "VAL_COLOR = \"#71067B\"\n",
    "\n",
    "COMBOS = [\n",
    "    (True,  True),\n",
    "    (False, False),\n",
    "    (True,  False),\n",
    "    (False, True),\n",
    "]\n",
    "\n",
    "# --- bool coercion robusto\n",
    "for col in [\"resize\", \"channels\", \"augment_train\"]:\n",
    "    if col in results_df.columns:\n",
    "        results_df[col] = (\n",
    "            results_df[col]\n",
    "            .map({\"True\": True, \"False\": False, \"1\": True, \"0\": False, 1: True, 0: False})\n",
    "            .fillna(results_df[col])\n",
    "            .astype(bool)\n",
    "        )\n",
    "\n",
    "required_cols = {\"pooling\", \"path\", \"resize\", \"channels\"}\n",
    "missing_cols = sorted(list(required_cols - set(results_df.columns)))\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Mancano colonne in results_all.csv: {missing_cols}\")\n",
    "\n",
    "def resolve_run_dir(p: str) -> str:\n",
    "    p = str(p).strip().replace(\"\\\\\", os.sep).replace(\"/\", os.sep)\n",
    "    if os.path.isabs(p) and os.path.exists(p):\n",
    "        return p\n",
    "    if os.path.exists(p):\n",
    "        return p\n",
    "    return os.path.join(base_dir, p)\n",
    "\n",
    "def load_history(run_dir: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(os.path.join(run_dir, \"history.csv\"))\n",
    "\n",
    "def aggregate_histories(df_subset: pd.DataFrame, phase: str):\n",
    "    \"\"\"Media±std su tutti i run in df_subset per una fase.\"\"\"\n",
    "    series_list = []\n",
    "\n",
    "    for _, row in df_subset.iterrows():\n",
    "        run_dir = resolve_run_dir(row[\"path\"])\n",
    "        hist_path = os.path.join(run_dir, \"history.csv\")\n",
    "        if not os.path.exists(hist_path):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            h = pd.read_csv(hist_path)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        if not {EPOCH_COL, PHASE_COL, LOSS_COL}.issubset(h.columns):\n",
    "            continue\n",
    "\n",
    "        hh = h[h[PHASE_COL].astype(str).str.lower() == phase.lower()].copy()\n",
    "        if hh.empty:\n",
    "            continue\n",
    "\n",
    "        hh = hh.sort_values(EPOCH_COL)\n",
    "        s = pd.Series(hh[LOSS_COL].values, index=hh[EPOCH_COL].values)\n",
    "        series_list.append(s)\n",
    "\n",
    "    if not series_list:\n",
    "        return None\n",
    "\n",
    "    common_epochs = set(series_list[0].index)\n",
    "    for s in series_list[1:]:\n",
    "        common_epochs &= set(s.index)\n",
    "    if not common_epochs:\n",
    "        return None\n",
    "\n",
    "    common_epochs = np.array(sorted(common_epochs))\n",
    "    mat = np.vstack([s.loc[common_epochs].values for s in series_list])\n",
    "    return common_epochs, mat.mean(axis=0), mat.std(axis=0, ddof=0), mat.shape[0]\n",
    "\n",
    "def plot_pooling_grid_train_val_2x2(pooling: str, out_dir: str, show_std=True, min_runs=1):\n",
    "    train_color = POOL_COLOR.get(pooling, \"#000000\")\n",
    "    val_color = VAL_COLOR\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10.5, 8.0), sharey=True)\n",
    "    fig.suptitle(f\"{pooling} — Loss vs Epoch\", fontsize=14, fontweight=\"bold\")\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    any_plotted = False\n",
    "\n",
    "    for ax, (r, c) in zip(axes, COMBOS):\n",
    "        df_sub = results_df[\n",
    "            (results_df[\"pooling\"].astype(str) == pooling) &\n",
    "            (results_df[\"resize\"] == r) &\n",
    "            (results_df[\"channels\"] == c)\n",
    "        ].copy()\n",
    "\n",
    "        n_total = len(df_sub)\n",
    "        agg_tr = aggregate_histories(df_sub, phase=\"train\")\n",
    "        agg_va = aggregate_histories(df_sub, phase=\"val\")\n",
    "\n",
    "        n_tr = agg_tr[3] if agg_tr is not None else 0\n",
    "        n_va = agg_va[3] if agg_va is not None else 0\n",
    "\n",
    "        ax.set_title(f\"resize={r}, channels={c}\\nruns: train={n_tr}, val={n_va} (tot={n_total})\", fontsize=10)\n",
    "\n",
    "        if agg_tr is not None and n_tr >= min_runs:\n",
    "            e, m, s, n = agg_tr\n",
    "            ax.plot(e, m, color=train_color, linewidth=2.5,\n",
    "                    label=\"train\" if (r, c) == COMBOS[0] else None)\n",
    "            if show_std and n > 1:\n",
    "                ax.fill_between(e, m - s, m + s, color=train_color, alpha=0.12)\n",
    "            any_plotted = True\n",
    "\n",
    "        if agg_va is not None and n_va >= min_runs:\n",
    "            e, m, s, n = agg_va\n",
    "            ax.plot(e, m, color=val_color, linewidth=2.5,\n",
    "                    label=\"val\" if (r, c) == COMBOS[0] else None)\n",
    "            if show_std and n > 1:\n",
    "                ax.fill_between(e, m - s, m + s, color=val_color, alpha=0.10)\n",
    "            any_plotted = True\n",
    "\n",
    "        ax.set_xlabel(\"epoch\")\n",
    "        ax.grid(True, alpha=0.25)\n",
    "\n",
    "    # y-label solo sulla colonna sinistra\n",
    "    for ax in axes[::2]:\n",
    "        ax.set_ylabel(\"loss\")\n",
    "\n",
    "    # legenda unica\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    if handles:\n",
    "        fig.legend(handles, labels, loc=\"lower center\", ncol=2, frameon=False)\n",
    "\n",
    "    # spazio sotto per legenda\n",
    "    plt.tight_layout(rect=[0, 0.08, 1, 0.92])\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_path = os.path.join(out_dir, f\"{pooling}.png\")\n",
    "    fig.savefig(out_path, dpi=240)\n",
    "    plt.close(fig)\n",
    "\n",
    "    if any_plotted:\n",
    "        print(\"Salvato:\", out_path)\n",
    "        return out_path\n",
    "    else:\n",
    "        print(f\"[WARN] Nessun dato plottabile per pooling={pooling}\")\n",
    "        return None\n",
    "\n",
    "out_dir = os.path.join(base_dir, \"loss_plots\")\n",
    "saved = []\n",
    "\n",
    "for p in POOLINGS:\n",
    "    outp = plot_pooling_grid_train_val_2x2(p, out_dir=out_dir, show_std=True, min_runs=1)\n",
    "    if outp is not None:\n",
    "        saved.append(outp)\n",
    "\n",
    "print(\"\\nout_dir =\", out_dir)\n",
    "print(\"Creati:\", len(saved), \"file\")\n",
    "for p in saved:\n",
    "    img = Image.open(p)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(os.path.basename(p), fontsize=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef7ab4e",
   "metadata": {
    "id": "5ef7ab4e"
   },
   "source": [
    "### **Tabelle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675d1cb7",
   "metadata": {
    "id": "675d1cb7",
    "outputId": "bea54d17-b4c1-4a17-83f3-1f04961fa14f"
   },
   "outputs": [],
   "source": [
    "# bool\n",
    "results_df[\"resize\"] = results_df[\"resize\"].map({\"True\": True, \"False\": False, \"1\": True, \"0\": False}).fillna(results_df[\"resize\"]).astype(bool)\n",
    "results_df[\"channels\"] = results_df[\"channels\"].map({\"True\": True, \"False\": False, \"1\": True, \"0\": False}).fillna(results_df[\"channels\"]).astype(bool)\n",
    "\n",
    "ACC_COL = \"test_bal_acc\"\n",
    "\n",
    "def make_block(df, resize_val, channels_val):\n",
    "    d = df[(df[\"resize\"] == resize_val) & (df[\"channels\"] == channels_val)].copy()\n",
    "    if ACC_COL in d.columns:\n",
    "        d = d.sort_values(ACC_COL, ascending=True, kind=\"mergesort\")\n",
    "    return d\n",
    "\n",
    "t00 = make_block(results_df, False, False)\n",
    "t01 = make_block(results_df, False, True)\n",
    "t10 = make_block(results_df, True,  False)\n",
    "t11 = make_block(results_df, True,  True)\n",
    "\n",
    "print(\"Righe:\", {\"r0c0\": len(t00), \"r0c1\": len(t01), \"r1c0\": len(t10), \"r1c1\": len(t11)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a6105f",
   "metadata": {
    "id": "c8a6105f",
    "outputId": "79b03e00-72ae-4cea-ae7a-deee16e101a7"
   },
   "outputs": [],
   "source": [
    "ACC_COL = \"test_bal_acc\"          # metrica principale\n",
    "LOSS_COL = [\"best_val_loss\"]\n",
    "\n",
    "DROP_COLS = {\"path\", \"test_acc\", \"test_weighted_acc\"}\n",
    "\n",
    "def table_rc(df, title, out_path, top_n=25, max_cols=14, dpi=220):\n",
    "    d = df.copy()\n",
    "\n",
    "    #  drop colonne\n",
    "    drop_here = [c for c in d.columns if c in DROP_COLS]\n",
    "    if drop_here:\n",
    "        d = d.drop(columns=drop_here)\n",
    "\n",
    "    loss_col = next((c for c in LOSS_COL if c in d.columns), None)\n",
    "\n",
    "    if ACC_COL in d.columns:\n",
    "        if loss_col is not None:\n",
    "            d = d.sort_values([ACC_COL, loss_col], ascending=[False, True], kind=\"mergesort\")\n",
    "        else:\n",
    "            d = d.sort_values(ACC_COL, ascending=False, kind=\"mergesort\")\n",
    "\n",
    "    d = d.head(top_n)\n",
    "\n",
    "    if max_cols is not None and d.shape[1] > max_cols:\n",
    "        d = d.iloc[:, :max_cols]\n",
    "\n",
    "    # best_epoch intero\n",
    "    if \"best_epoch\" in d.columns:\n",
    "        d[\"best_epoch\"] = pd.to_numeric(d[\"best_epoch\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    # format per rendering (stringhe)\n",
    "    r = d.copy()\n",
    "    for col in r.columns:\n",
    "        if pd.api.types.is_float_dtype(r[col]):\n",
    "            r[col] = r[col].map(lambda x: f\"{x:.2f}\" if pd.notnull(x) else \"\")\n",
    "        elif col == \"best_epoch\":\n",
    "            r[col] = r[col].map(lambda x: f\"{int(x)}\" if pd.notnull(x) else \"\")\n",
    "        else:\n",
    "            r[col] = r[col].map(lambda x: \"\" if pd.isna(x) else str(x))\n",
    "\n",
    "    nrows, ncols = r.shape\n",
    "\n",
    "    # figura proporzionata\n",
    "    fig_w = max(10, 1.05 * ncols + 2)\n",
    "    fig_h = max(3.2, 0.42 * (nrows + 2))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(fig_w, fig_h), dpi=dpi)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    # titolo con best test_bal_acc\n",
    "    subtitle = \"\"\n",
    "    if ACC_COL in d.columns and len(d) > 0 and pd.notnull(d[ACC_COL].iloc[0]):\n",
    "        subtitle = f\" — best {ACC_COL}: {d[ACC_COL].iloc[0]:.4f}\"\n",
    "    ax.set_title(f\"{title}{subtitle}\", pad=14, fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "    tbl = ax.table(\n",
    "        cellText=r.values,\n",
    "        colLabels=r.columns,\n",
    "        loc=\"center\",\n",
    "        cellLoc=\"center\",\n",
    "        colLoc=\"center\",\n",
    "    )\n",
    "\n",
    "    tbl.auto_set_font_size(False)\n",
    "    tbl.set_fontsize(9)\n",
    "\n",
    "    try:\n",
    "        tbl.auto_set_column_width(col=list(range(ncols)))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    header_h = 0.06\n",
    "    body_h = 0.048\n",
    "\n",
    "    # la migliore è la prima riga del body\n",
    "    best_row = 1  # 0 è header\n",
    "\n",
    "    for (row, col), cell in tbl.get_celld().items():\n",
    "        cell.set_linewidth(0.4)\n",
    "\n",
    "        if row == 0:\n",
    "            cell.set_height(header_h)\n",
    "            cell.set_text_props(fontweight=\"bold\")\n",
    "            cell.set_facecolor(\"#f0f0f0\")\n",
    "        else:\n",
    "            cell.set_height(body_h)\n",
    "            cell.set_facecolor(\"#fbfbfb\" if row % 2 == 0 else \"white\")\n",
    "\n",
    "            if row == best_row:\n",
    "                cell.set_facecolor(\"#a4a8f3\")\n",
    "\n",
    "    tbl.scale(1.05, 1.15)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    plt.savefig(out_path, bbox_inches=\"tight\", pad_inches=0.2)\n",
    "    plt.close(fig)\n",
    "\n",
    "out_dir = os.path.join(base_dir, \"tables_png\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "table_rc(t00, \"resize=False, channels=False\", os.path.join(out_dir, \"t00.png\"), top_n=25)\n",
    "table_rc(t01, \"resize=False, channels=True\",  os.path.join(out_dir, \"t01.png\"), top_n=25)\n",
    "table_rc(t10, \"resize=True,  channels=False\", os.path.join(out_dir, \"t10.png\"), top_n=25)\n",
    "table_rc(t11, \"resize=True,  channels=True\",  os.path.join(out_dir, \"t11.png\"), top_n=25)\n",
    "\n",
    "print(\"PNG salvati in:\", out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568a5f41",
   "metadata": {
    "id": "568a5f41"
   },
   "source": [
    "### **CONFUSION MATRIX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d6ec06",
   "metadata": {
    "id": "76d6ec06",
    "outputId": "35580ca6-ce7a-45bd-a250-19731fb336d6"
   },
   "outputs": [],
   "source": [
    "base_dir = \"results_bestvalloss\"\n",
    "res = \"results_all.csv\"\n",
    "path = os.path.join(base_dir, res)\n",
    "results_df = pd.read_csv(path)\n",
    "\n",
    "def pick_best_row(results_df):\n",
    "    d = results_df.dropna(subset=[\"test_bal_acc\"]).copy()\n",
    "\n",
    "    d[\"test_bal_acc\"] = d[\"test_bal_acc\"].round(2)\n",
    "\n",
    "    d = d.sort_values([\"test_bal_acc\", \"best_val_loss\"],\n",
    "                      ascending=[False,True],\n",
    "                      kind=\"mergesort\")\n",
    "    return d.iloc[0]\n",
    "\n",
    "def best_run_dir_from_row(best):\n",
    "    # path\n",
    "    if \"path\" in best.index and pd.notna(best[\"path\"]):\n",
    "        return str(best[\"path\"])\n",
    "\n",
    "best = pick_best_row(results_df)\n",
    "best_run_dir = best_run_dir_from_row(best)\n",
    "\n",
    "cm_path = os.path.join(best_run_dir, \"cm_test.csv\")\n",
    "print(\"Best run:\", best_run_dir)\n",
    "print(\"Uso CM da:\", cm_path)\n",
    "print(\"Criterio sort:\", \"test_bal_acc desc, best_val_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72263b17",
   "metadata": {
    "id": "72263b17",
    "outputId": "b5f2c66d-ee1a-453a-a9d0-1e6f8c96f493"
   },
   "outputs": [],
   "source": [
    "ID2LABEL = {v: k for k, v in LABEL_MAP.items()}\n",
    "n_classes = 3\n",
    "class_names = [ID2LABEL[i] for i in range(n_classes)]\n",
    "\n",
    "cm_df = pd.read_csv(cm_path)\n",
    "\n",
    "# prova a isolare 3x3 anche se il CSV ha colonne extra\n",
    "cm_df = cm_df.select_dtypes(include=[np.number])\n",
    "cm_df = cm_df.iloc[:n_classes, :n_classes]\n",
    "cm = cm_df.to_numpy(dtype=int)\n",
    "\n",
    "plt.figure(figsize=(3.3, 3.0), dpi=260)\n",
    "im = plt.imshow(cm, cmap=\"Blues\", vmin=0, vmax=max(1, cm.max()))\n",
    "plt.colorbar(im, fraction=0.05, pad=0.03)\n",
    "\n",
    "plt.xticks(range(n_classes), class_names, rotation=20, ha=\"right\", fontsize=7)\n",
    "plt.yticks(range(n_classes), class_names, fontsize=7)\n",
    "plt.xlabel(\"Predicted Label\", fontsize=8)\n",
    "plt.ylabel(\"True Label\", fontsize=8)\n",
    "plt.suptitle(\"CM — Stochastic\\nResize: True / Channel True / No Aug\", fontsize=9, fontweight=\"bold\", y=1.02)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "ax.set_xticks(np.arange(-.5, n_classes, 1), minor=True)\n",
    "ax.set_yticks(np.arange(-.5, n_classes, 1), minor=True)\n",
    "ax.grid(which=\"minor\", color=\"black\", linestyle=\"-\", linewidth=0.8)\n",
    "ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "\n",
    "thr = cm.max() * 0.55\n",
    "for i in range(n_classes):\n",
    "    for j in range(n_classes):\n",
    "        val = cm[i, j]\n",
    "        color = \"white\" if (cm.max() > 0 and val >= thr) else \"black\"\n",
    "        ax.text(j, i, str(val), ha=\"center\", va=\"center\",\n",
    "                fontsize=8, fontweight=\"bold\", color=color)\n",
    "\n",
    "for s in ax.spines.values():\n",
    "    s.set_visible(True)\n",
    "    s.set_color(\"black\")\n",
    "    s.set_linewidth(1.2)\n",
    "\n",
    "plt.tight_layout(pad=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a952d39d",
   "metadata": {
    "id": "a952d39d",
    "outputId": "4f321a2c-8d01-48b3-9f83-efdbf14c659b"
   },
   "outputs": [],
   "source": [
    "ACC_COL = \"test_bal_acc\"\n",
    "\n",
    "# filtro ESATTO: solo \"max\"\n",
    "dmax = results_df[\n",
    "    results_df[\"pooling\"].astype(str).str.strip().str.lower().eq(\"max\")\n",
    "].copy()\n",
    "\n",
    "if dmax.empty:\n",
    "    raise ValueError(\"Nessun run con pooling == 'max' trovato (controlla i valori della colonna 'pooling').\")\n",
    "\n",
    "sort_cols = [ACC_COL] + ([\"best_val_loss\"] if \"best_val_loss\" in dmax.columns else [])\n",
    "ascending = [False] + ([True] if \"best_val_loss\" in dmax.columns else [])\n",
    "\n",
    "best_max = (\n",
    "    dmax.dropna(subset=[ACC_COL])\n",
    "       .sort_values(sort_cols, ascending=ascending, kind=\"mergesort\")\n",
    "       .iloc[0]\n",
    ")\n",
    "\n",
    "best_run_dir = str(best_max[\"path\"])\n",
    "cm_path = os.path.join(best_run_dir, \"cm_test.csv\")\n",
    "\n",
    "print(\"Best MAX run:\", best_run_dir)\n",
    "print(\"Best MAX test_bal_acc:\", float(best_max[ACC_COL]))\n",
    "print(\"CM file:\", cm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767ef0c6",
   "metadata": {
    "id": "767ef0c6",
    "outputId": "1e8b79ff-7488-4a4c-ec71-1ba5f190cbf1"
   },
   "outputs": [],
   "source": [
    "ID2LABEL = {v: k for k, v in LABEL_MAP.items()}\n",
    "n_classes = 3\n",
    "class_names = [ID2LABEL[i] for i in range(n_classes)]\n",
    "\n",
    "cm_df = pd.read_csv(cm_path)\n",
    "\n",
    "# isola 3x3 anche se il CSV ha colonne extra\n",
    "cm_df = cm_df.select_dtypes(include=[np.number])\n",
    "cm_df = cm_df.iloc[:n_classes, :n_classes]\n",
    "cm = cm_df.to_numpy(dtype=int)\n",
    "\n",
    "# --- plot ---\n",
    "plt.figure(figsize=(3.3, 3.0), dpi=260)\n",
    "im = plt.imshow(cm, cmap=\"Blues\", vmin=0, vmax=max(1, cm.max()))\n",
    "plt.colorbar(im, fraction=0.05, pad=0.03)\n",
    "\n",
    "plt.xticks(range(n_classes), class_names, rotation=20, ha=\"right\", fontsize=7)\n",
    "plt.yticks(range(n_classes), class_names, fontsize=7)\n",
    "plt.xlabel(\"Predicted Label\", fontsize=8)\n",
    "plt.ylabel(\"True Label\", fontsize=8)\n",
    "\n",
    "# titolo coerente col best_max selezionato\n",
    "rz = int(best_max[\"resize\"]) if \"resize\" in best_max else None\n",
    "ch = int(best_max[\"channels\"]) if \"channels\" in best_max else None\n",
    "\n",
    "# a volte la colonna si chiama augment_train, a volte aug\n",
    "if \"augment_train\" in best_max:\n",
    "    aug = int(best_max[\"augment_train\"])\n",
    "elif \"aug\" in best_max:\n",
    "    aug = int(best_max[\"aug\"])\n",
    "else:\n",
    "    aug = None\n",
    "\n",
    "aug_txt = (\"Aug: True\" if aug == 1 else \"No Aug\") if aug is not None else \"Aug: ?\"\n",
    "rz_txt  = (\"Resize: True\" if rz == 1 else \"Resize: False\") if rz is not None else \"Resize: ?\"\n",
    "ch_txt  = (\"Channel True\" if ch == 1 else \"Channel False\") if ch is not None else \"Channel ?\"\n",
    "\n",
    "plt.suptitle(\n",
    "    f\"CM — MAX\\n{rz_txt} / {ch_txt} / {aug_txt}\",\n",
    "    fontsize=9, fontweight=\"bold\", y=1.02\n",
    ")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "ax.set_xticks(np.arange(-.5, n_classes, 1), minor=True)\n",
    "ax.set_yticks(np.arange(-.5, n_classes, 1), minor=True)\n",
    "ax.grid(which=\"minor\", color=\"black\", linestyle=\"-\", linewidth=0.8)\n",
    "ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "\n",
    "thr = cm.max() * 0.55\n",
    "for i in range(n_classes):\n",
    "    for j in range(n_classes):\n",
    "        val = cm[i, j]\n",
    "        color = \"white\" if (cm.max() > 0 and val >= thr) else \"black\"\n",
    "        ax.text(j, i, str(val), ha=\"center\", va=\"center\",\n",
    "                fontsize=8, fontweight=\"bold\", color=color)\n",
    "\n",
    "for s in ax.spines.values():\n",
    "    s.set_visible(True)\n",
    "    s.set_color(\"black\")\n",
    "    s.set_linewidth(1.2)\n",
    "\n",
    "plt.tight_layout(pad=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861448d8",
   "metadata": {
    "id": "861448d8"
   },
   "source": [
    "### **GRAD-CAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244bf187",
   "metadata": {
    "id": "244bf187",
    "outputId": "4b00e22c-e778-4f76-a1c9-9eff182b6438"
   },
   "outputs": [],
   "source": [
    "ACC_COL = \"test_bal_acc\"\n",
    "\n",
    "target = model.layer4[-1]\n",
    "\n",
    "dmax = results_df[\n",
    "    results_df[\"pooling\"].astype(str).str.strip().str.lower().eq(\"max\")\n",
    "].copy()\n",
    "\n",
    "if dmax.empty:\n",
    "    raise ValueError(\"Nessun run con pooling == 'max' trovato.\")\n",
    "\n",
    "# tie-breaker su best_val_loss\n",
    "sort_cols = [ACC_COL] + ([\"best_val_loss\"] if \"best_val_loss\" in dmax.columns else [])\n",
    "ascending = [False] + ([True] if \"best_val_loss\" in dmax.columns else [])\n",
    "\n",
    "best_max = (\n",
    "    dmax.dropna(subset=[ACC_COL])\n",
    "        .sort_values(sort_cols, ascending=ascending, kind=\"mergesort\")\n",
    "        .iloc[0]\n",
    ")\n",
    "\n",
    "best_run_dir = str(best_max[\"path\"])\n",
    "ckpt_path = os.path.join(best_run_dir, \"best_model.pt\")\n",
    "print(\"Grad-CAM: BEST MAX run =\", best_run_dir)\n",
    "print(\"Checkpoint:\", ckpt_path)\n",
    "print(\"Best MAX test_bal_acc:\", float(best_max[ACC_COL]))\n",
    "\n",
    "# modello + checkpoint\n",
    "model = ResNet18(num_classes=NUM_CLASSES).to(device)\n",
    "state = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "if isinstance(state, dict) and \"state_dict\" in state:\n",
    "    state = state[\"state_dict\"]\n",
    "elif isinstance(state, dict) and \"model_state_dict\" in state:\n",
    "    state = state[\"model_state_dict\"]\n",
    "\n",
    "# rimuovi eventuale prefix \"module.\"\n",
    "state = {k.replace(\"module.\", \"\"): v for k, v in state.items()}\n",
    "model.load_state_dict(state, strict=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bd10e3",
   "metadata": {
    "id": "c1bd10e3",
    "outputId": "e0b3aef6-e25e-4afe-ba5a-41deeb97f5d2"
   },
   "outputs": [],
   "source": [
    "def pick_test_image_for_label(df_test, label_id, seed=None):\n",
    "    label_col = \"label_id\" if \"label_id\" in df_test.columns else \"label\"\n",
    "\n",
    "    rows = df_test[df_test[label_col] == label_id]\n",
    "    if rows.empty:\n",
    "        raise ValueError(f\"Nessuna immagine con label {label_id}\")\n",
    "\n",
    "    if seed is not None:\n",
    "        rows = rows.sample(1, random_state=seed)\n",
    "    else:\n",
    "        rows = rows.sample(1)   # RANDOM ogni volta\n",
    "\n",
    "    row = rows.iloc[0]\n",
    "\n",
    "    if \"path\" in row:\n",
    "        img_path = row[\"path\"]\n",
    "    elif \"img_path\" in row:\n",
    "        img_path = row[\"img_path\"]\n",
    "    elif \"id\" in row:\n",
    "        img_path = os.path.join(img_dir, f\"img_{int(row['id'])}.png\")\n",
    "    else:\n",
    "        raise ValueError(\"Non trovo il path immagine.\")\n",
    "\n",
    "    return img_path, row\n",
    "\n",
    "\n",
    "target_layers = [model.layer4[-1]]\n",
    "cam = GradCAM(model=model, target_layers=target_layers)\n",
    "\n",
    "target_layers = [model.layer4[-1]]\n",
    "cam = GradCAM(model=model, target_layers=target_layers)\n",
    "\n",
    "def gradcam_for_class(label_id):\n",
    "    # seleziona immagine dal test (una per quella label)\n",
    "    img_path, row = pick_test_image_for_label(df_test, label_id)\n",
    "\n",
    "    dataset_cam = CustomDataset(\n",
    "        df_test.loc[[row.name]],\n",
    "        img_dir=img_dir,\n",
    "        img_size=224,\n",
    "        is_train=False,\n",
    "        augment=False,\n",
    "        resize=bool(best_max[\"resize\"]),\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "    )\n",
    "\n",
    "    input_tensor, y_true = dataset_cam[0]\n",
    "    input_tensor = input_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "    # immagine per overlay (non normalizzata)\n",
    "    img_bgr = cv2.imread(img_path)\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    img_rgb = cv2.resize(img_rgb, (224, 224))\n",
    "    rgb_float = img_rgb.astype(np.float32) / 255.0\n",
    "\n",
    "    #  PRED\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)\n",
    "        pred_class = int(torch.argmax(logits, dim=1).item())\n",
    "\n",
    "    targets = [ClassifierOutputTarget(pred_class)]\n",
    "\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0]\n",
    "    overlay = show_cam_on_image(rgb_float, grayscale_cam, use_rgb=True, image_weight=0.35)\n",
    "\n",
    "    return img_rgb, overlay, int(y_true), pred_class\n",
    "\n",
    "ID2LABEL = {v: k for k, v in LABEL_MAP.items()}\n",
    "\n",
    "for label_id in range(3):\n",
    "    orig, cam_img, y_true, pred = gradcam_for_class(label_id)\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(f\"Original | true={ID2LABEL[y_true]}\")\n",
    "    plt.imshow(orig); plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title(f\"Grad-CAM MAXPOOL | pred={ID2LABEL[pred]}\")\n",
    "    plt.imshow(cam_img); plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a988b6d7",
   "metadata": {
    "id": "a988b6d7",
    "outputId": "0e8f0eb1-322a-469f-dcc9-3295e3fb552d"
   },
   "outputs": [],
   "source": [
    "df0 = results_df.copy()\n",
    "\n",
    "# filtra stochastic\n",
    "dstoch = df0[df0[\"pooling\"].astype(str).str.strip().str.lower().eq(\"stochastic\")].copy()\n",
    "if dstoch.empty:\n",
    "    raise ValueError(\"Nessun run con pooling == 'stochastic' trovato.\")\n",
    "\n",
    "dstoch = dstoch.dropna(subset=[ACC_COL, \"path\"]).copy()\n",
    "if \"best_val_loss\" in dstoch.columns:\n",
    "    dstoch = dstoch.dropna(subset=[\"best_val_loss\"]).copy()\n",
    "\n",
    "dstoch[\"_acc2\"] = dstoch[ACC_COL].round(2)\n",
    "\n",
    "# max su acc arrotondata\n",
    "best_acc2 = dstoch[\"_acc2\"].max()\n",
    "cand = dstoch[dstoch[\"_acc2\"] == best_acc2].copy()\n",
    "\n",
    "if \"best_val_loss\" in cand.columns:\n",
    "    cand = cand.sort_values([\"best_val_loss\", ACC_COL], ascending=[True, False], kind=\"mergesort\")\n",
    "else:\n",
    "    cand = cand.sort_values([ACC_COL], ascending=[False], kind=\"mergesort\")\n",
    "\n",
    "best_stoch = cand.iloc[0].drop(labels=[\"_acc2\"])\n",
    "\n",
    "best_run_dir = str(best_stoch[\"path\"])\n",
    "ckpt_path = os.path.join(best_run_dir, \"best_model.pt\")\n",
    "\n",
    "print(\"BEST STOCHASTIC (acc2=%.2f):\" % best_acc2)\n",
    "print(\"run:\", best_run_dir)\n",
    "print(\"test_bal_acc:\", float(best_stoch[ACC_COL]))\n",
    "if \"best_val_loss\" in best_stoch:\n",
    "    print(\"best_val_loss:\", float(best_stoch[\"best_val_loss\"]))\n",
    "print(\"ckpt:\", ckpt_path)\n",
    "\n",
    "model = ResNet18(num_classes=NUM_CLASSES).to(device)\n",
    "state = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "if isinstance(state, dict) and \"state_dict\" in state:\n",
    "    state = state[\"state_dict\"]\n",
    "elif isinstance(state, dict) and \"model_state_dict\" in state:\n",
    "    state = state[\"model_state_dict\"]\n",
    "\n",
    "state = {k.replace(\"module.\", \"\"): v for k, v in state.items()}\n",
    "model.load_state_dict(state, strict=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db59f296",
   "metadata": {
    "id": "db59f296",
    "outputId": "f74d2370-7520-46a1-de28-a796c97c09cd"
   },
   "outputs": [],
   "source": [
    "def tensor_to_rgb(x,mean,std):\n",
    "    if x.dim() == 4:\n",
    "        x = x[0]\n",
    "    x = x.detach().cpu().float()\n",
    "\n",
    "    mean_t = torch.tensor(mean).view(-1,1,1)\n",
    "    std_t = torch.tensor(std).view(-1,1,1)\n",
    "\n",
    "    x = x * std_t + mean_t\n",
    "    x = x.clamp(0,1)\n",
    "    rgb = x.permute(1,2,0).numpy()\n",
    "    return rgb\n",
    "\n",
    "\n",
    "def pick_test_image_for_label(df_test, label_id, seed=None):\n",
    "    label_col = \"label_id\" if \"label_id\" in df_test.columns else \"label\"\n",
    "\n",
    "    rows = df_test[df_test[label_col] == label_id]\n",
    "    if rows.empty:\n",
    "        raise ValueError(f\"Nessuna immagine con label {label_id}\")\n",
    "\n",
    "    row = rows.sample(1, random_state=seed).iloc[0] if seed is not None else rows.sample(1).iloc[0]\n",
    "\n",
    "    if \"path\" in row:\n",
    "        img_path = row[\"path\"]\n",
    "    elif \"img_path\" in row:\n",
    "        img_path = row[\"img_path\"]\n",
    "    elif \"id\" in row:\n",
    "        img_path = os.path.join(img_dir, f\"img_{int(row['id'])}.png\")\n",
    "    else:\n",
    "        raise ValueError(\"Non trovo il path immagine.\")\n",
    "\n",
    "    return img_path, row\n",
    "\n",
    "target_layers = [model.layer4[-1]]\n",
    "cam = GradCAM(model=model, target_layers=target_layers)\n",
    "\n",
    "def gradcam_for_class_stochastic(label_id):\n",
    "    img_path, row = pick_test_image_for_label(df_test, label_id)\n",
    "\n",
    "    dataset_cam = CustomDataset(\n",
    "        df_test.loc[[row.name]],\n",
    "        img_dir=img_dir,\n",
    "        img_size=224,\n",
    "        is_train=False,\n",
    "        augment=False,\n",
    "        resize=bool(best_stoch[\"resize\"]),\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "    )\n",
    "\n",
    "    input_tensor, y_true = dataset_cam[0]\n",
    "    input_tensor = input_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "    # overlay image (NON normalizzata)\n",
    "    rgb_float = tensor_to_rgb(input_tensor,mean,std)\n",
    "\n",
    "    # PRED reale\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)\n",
    "        pred_class = int(torch.argmax(logits, dim=1).item())\n",
    "\n",
    "    targets = [ClassifierOutputTarget(pred_class)]\n",
    "\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0]\n",
    "    overlay = show_cam_on_image(\n",
    "        rgb_float,\n",
    "        grayscale_cam,\n",
    "        use_rgb=True,\n",
    "        image_weight=0.35\n",
    "    )\n",
    "\n",
    "    return rgb_float, overlay, int(y_true), pred_class\n",
    "\n",
    "ID2LABEL = {v: k for k, v in LABEL_MAP.items()}\n",
    "\n",
    "for label_id in range(3):\n",
    "    orig, cam_img, y_true, pred = gradcam_for_class_stochastic(label_id)\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(f\"Original | true={ID2LABEL[y_true]}\")\n",
    "    plt.imshow(orig); plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title(f\"Grad-CAM STOCHASTIC | pred={ID2LABEL[pred]}\")\n",
    "    plt.imshow(cam_img); plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}